
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about",
    "title": "",
    "body": "Notion 포트폴리오 입니다.  자세한 사항은 우측의 Portfolio를 클릭해주세요! Learn More: Please, read the my portfolio here. Hello, World!Thank you for visiting my blog! If you want to contact me, 📬 dnwjd6452@gmail. com LinkedInNotion-Portfolio"
    }, {
    "id": 2,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                                             My Diary                              :               :                                                                                                                                                                       Liam                                25 Sep 2022                                                                                                                                                                                                                                        All Stories:                                                                                                     React 학습하기              :       💡 Intro 백앤드 개발을 하면서 간단한 Admin 사이트를 개발하는 경우가 종종 있는데, 단순 javascript로 개발한 어드민은 생각보다 많은 리소스가 들어간다는 느낌을 받았습니다. 그래서 사용자에게는 조금 더 나은 경험을 줄 수. . . :                                                                               Liam                11 Feb 2023                                                                                                                                    주니어 개발자의 조금 늦은 2022년 회고              :       💡 Intro 2022년 말 회고록에 대해서 알게 되었습니다. 한 해 간 있었던 제 자신을 되돌아볼 수 있게 해준다는 점에서 연말에 꼭 한번 써보겠다는 생각을 가졌습니다. 정작 연말에는 갖가지 핑계로 안하고. . . :                                                                               Liam                03 Jan 2023                                                                                                                                    What is Apache Kafka?              :       💡 IntroKafka는 많은 서비스에서 백엔드로 사용하고 있습니다. 저는 Kafka의 ‘K’ 정도만 알고 있기 때문에, 오늘은 Kafka의 개념과 기본 구조에 대해서 알아보려고 합니다. :                                                                               Liam                10 Dec 2022                                                                                                                                    스트리밍 서비스와 AWS Media Services              :       💡 Intro Youtube를 보다가 정말 정말 갑자기 스트리밍 서비스에 대해 궁금해졌습니다. 단순히 CDN(Content Delivery Network)을 사용한다 정도만 알고 있었는데, 조금 자세하게 공부를 해보려 합니다. 🔎 스트리밍(Streaming) 이란? 스트리밍 서비스란 인터넷에서. . . :                                                                               Liam                15 Sep 2022                                                                                                                                    ALB(Application Load Balancer)에서 URL 기반 라우팅              :       💡 Intro 하나의 도메인에 두 개의 서비스를 할 수 있는지에 대해 묻는 분이 있었습니다. AWS에서 어떻게 구성해야 하는지 🌎AWS Docs를 찾아보다가 ALB(Application Load Balancer)로 가능하다는 것을알게 되었습니다. 이를 URL 기반. . . :                                                                               Liam                31 Aug 2022                                                                                                                                    VPC내의 AWS Lambda의 인터넷 접속하기              :       💡 Intro Amazon Virtual Private Cloud(Amazon VPC)에 연결된 AWS Lambda에 인터넷 접속을 가능하게 하려면, NAT GW(Network Address Translation Gateway) 설정을 해야합니다. 오늘은 이에 대해서 정리해 보려고 합니다. 🔎 AWS Lambda의. . . :                                                                               Liam                19 Aug 2022                                               &laquo; Prev       1        2        3        4      Next &raquo; "
    }, {
    "id": 4,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 5,
    "url": "http://localhost:4000/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "http://localhost:4000/page4/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "http://localhost:4000/react/",
    "title": "React 학습하기",
    "body": "2023/02/11 -  💡 Intro: 백앤드 개발을 하면서 간단한 Admin 사이트를 개발하는 경우가 종종 있는데, 단순 javascript로 개발한 어드민은 생각보다 많은 리소스가 들어간다는 느낌을 받았습니다. 그래서 사용자에게는 조금 더 나은 경험을 줄 수 있고, 개발자에게도 더 나은 유지 보수와 생산성을 줄 수 있는 SPA(Single Page Application)를 위한 React에 대해 공부해보려 합니다.  🔎 React를 쓰는 이유는?: 흔히들 🌎React는 SPA(Single Page Application)를 위해 많이 쓴다고들 하는데, SPA란 새로운 페이지를 불러오는 것이 아니라 페이지를 동적으로 작성해서 사용자와 소통할 수 있는 조금 더 자연스러운 웹 애플리케이션 이나 웹사이트를 의미합니다. 기존의 웹 방식은 새로운 페이지를 요청할 때마다 리소스를 다운로드하고 받은 리소스를 렌더링 하면서 변경이 필요 없는 부분들을 포함하기 때문에 상당히 비효율적 이었는데 SPA가 나오면서 웹 애플리케이션에 필요한 모든 정적 리소스를 최초에 한번 다운로드 하고, 이후에 새로운 페이지 요청 시 페이지 갱신에 필요한 데이터만을 전달받아 페이지를 갱신하게 되었습니다. 이러한 이유로 React의 가장 큰 특징인 Virtual DOM이 있습니다. 기존의 DOM은 페이지가 바뀔 때마다 새 HTML를 로드하면서 리랜더링 하는데, Virtual Dom은 React Component가 리턴하는 값에 의해 만들어져서 실제 보이고 있는 DOM과 비교해서 달라진 부분만 찾아서 반영합니다. 또한 Virtual Dom으로 인해 개발을 Component 단위로 작성할 수 있게됩니다. 컴포넌트는 UI를 구성하는 개별적인 뷰 단위인데, UI 개발을 조립하듯이 만들어줍니다. 이렇게 나누어진 컴포넌트 들로인해 다른 필요한 부분들에 재사용이 가능해지고, 이는 생산성과 유지보수를 향상시켜줍니다. 그렇게 각각의 컴포넌트들이 결합하여 하나의 View를 보여줍니다.  🔎 React 시작하기: React 작업 환경 세팅: Node. js가 깔려있다는 것을 전재로 가벼운 예제로 React를 시작해 보려합니다. 이미지 1. Node. js / npm version 일반적으로 다음 명령어를 통해 react 프로젝트를 시작하지만, 1$ npx create-react-app my-app저는 타입스크립트의 사용성에 익숙해지기 위해 React에서 typescript 명령어를 입력했습니다. 1$ npx create-react-app my-app --template typescript이미지 2. Begin React npx create-react-app my-app --template typescript를 입력하면 Success 메세지와 함께 my-app 디렉터리속 React Project가 생성됩니다. 1$ npx start그 후 이 명령어를 통해 http://localhost:3000/가 열리면서 뺑글 뺑글 돌고 있는 React 아이콘을 볼 수 있습니다. 이미지 3. 나의 첫 React 웹 간단한 예제로 React TypeScript 연습: 1. Counter: 우선 my-app/src/App. tsx로 가면 http://localhost:3000/에서 보았던 텍스트와 로고가 있는 코드를 볼 수 있습니다. 1234567891011121314151617181920212223242526import React from 'react';import logo from '. /logo. svg';import '. /App. css';function App() { return (  &lt;div className= App &gt;   &lt;header className= App-header &gt;    &lt;img src={logo} className= App-logo  alt= logo  /&gt;    &lt;p&gt;     Edit &lt;code&gt;src/App. tsx&lt;/code&gt; and save to reload.     &lt;/p&gt;    &lt;a     className= App-link      href= https://reactjs. org      target= _blank      rel= noopener noreferrer     &gt;     Learn React    &lt;/a&gt;   &lt;/header&gt;  &lt;/div&gt; );}export default App;App. tsx를 다음과 같이 작성해 줍니다. 12345678910111213import * as React from 'react';import { Counter } from '. /Counter';const App = () =&gt; { return (  &lt;div className='App'&gt;   &lt;Counter /&gt;  &lt;/div&gt; );};export default App;그리고 src/Counter. tsx 파일을 생성하여 다음과 같은 코드를 작성합니다. 12345678910111213141516171819202122232425262728293031323334353637import * as React from 'react';import { useState } from 'react';interface Istate {  counter: number}export function Counter() {  const [state, setState] = useState&lt;Istate&gt;({ //[상태 값 저장 변수, 상태 값 갱신 함수] = useState(상태 초기 값);    counter: 0  })  const onIncrement = () =&gt; {    setState({      counter: state. counter+1    })  }  const onDecrement = () =&gt; {    setState({      counter: state. counter-1    })  }  return(    &lt;div&gt;      &lt;h2&gt;Counter&lt;/h2&gt;      &lt;div&gt;        {state. counter}      &lt;/div&gt;      &lt;div&gt;        &lt;button onClick={onIncrement}&gt;+&lt;/button&gt;        &lt;button onClick={onDecrement}&gt;-&lt;/button&gt;      &lt;/div&gt;    &lt;/div&gt;  )} 리액트 컴포넌트에서 동적인 값을 상태(state)라고 부르는데, 사용자 인터랙션을 통해 컴포넌트의 상태 값이 동적으로 바뀔 경우에 상태 관리가 필요합니다. 원래 상태 값을 관리하기 위해 클래스 기반의 컴포넌트를 사용하였지만, 유지 보수가 힘들다는 단점이 있었습니다. 그래서 Hooks라는 기능이 추가되었고 Hooks의 useState() 함수를 통해 컴포넌트에서 바뀌는 값을 관리할 수 있게 되었습니다.   끝맺음 [참고자료]  facebook/create-react-app 타입스크립트 React-TypeScript Docs 벨로퍼트와 함께하는 모던 리액트 [ React ] useState는 어떻게 동작할까"
    }, {
    "id": 8,
    "url": "http://localhost:4000/reminiscence/",
    "title": "주니어 개발자의 조금 늦은 2022년 회고",
    "body": "2023/01/03 -  💡 Intro: 2022년 말 회고록에 대해서 알게 되었습니다. 한 해 간 있었던 제 자신을 되돌아볼 수 있게 해준다는 점에서 연말에 꼭 한번 써보겠다는 생각을 가졌습니다. 정작 연말에는 갖가지 핑계로 안하고 있었는데 아직 늦지 않았다는 이야기를 듣고, 마음을 새로 바로잡아 조금 늦었지만 2022년을 회고해 보려 합니다.  🔎 신입개발자의 회고: 지금 생각해 보면 저에게 2022년은 정말 많은 일이 있었던 한 해였고, 인생에 중요한 기점이 여러번 있었던 해였던 것 같습니다. 저의 첫 회사는 알파도라는 회사였는데, AOS 개발자 한분, iOS 개발자 한분, 서버 개발자는 저 한 명 이렇게 3명의 개발자가 존재했었습니다. 각 직군에 한 명뿐 이었기 때문에, 서로에게 의지를 많이 했었는데 이때 소통하는 방법을 많이 배웠던 것 같습니다. 비록 각자 분야는 다르지만, 프로젝트마다 서로에게 필요한 것을 같이 찾아 주며 함께 공부하면서 더욱 돈독해 질 수 있었던 것 같습니다. (지금 쓰고 있는 블로그도 이때 다 같이 시작했습니다. 😀)하지만 4월쯤 회사의 사정이 안 좋아지면서 7월에 다 같이 퇴사를 했었는데, 저희는 아무것도 들은 것이 없던 상태에서 갑작스럽게 퇴사 통보를 받으면서 아쉬운 마음을 느낄 새도 없이 어리둥절한 상태로 나간것 같습니다.  후에 실업 급여를 위해 퇴사 내용을 정리하면서, 함께 지내던 개발자들과 처음으로 떨어졌다는 것과 지금까지 열심히 만든 프로젝트의 결과물이 세상에 나가지 못했다는 것이 못내 조금 아쉬웠습니다. 그렇게 8월부터는 외주를 진행하며 취업 준비를 하다가, 10월에 열리는 파이콘이라는 행사를 알게 되고 서울에 있는 친구와 처음으로 파이콘 행사를 가게 되었는데, 이곳에서 정말 큰 행운을 가질 수 있었습니다. 행사를 진행하던 도중 취업 박람회라는 세션에서 현재 재가 재직중인 🌏닷슬래시대시의 리더 개발자 님과 primmadonna 개발자님을 만나게 되었습니다. 여러 궁금했던 것에 대해 정말 친절히 대답해 주셨고, 회사에 지원을 해볼 수 있는 기회를 주셨습니다. 파이콘 행사 후기(가장 아래 부분) 한 달간의 커피챗과 테스트, 면접을 진행하며 저와는 비교도 안될 정도로 성숙한 분들이라는 것을 알 수 있었고 함께 일할 수 있다면 정말 좋겠다는 생각을 가졌을 찰나! 10월 말 합격했다는 이야기를 들었습니다. (아마 근 5개월 동안 가장 기뻤었던 걸로 기억합니다. 👯)11월 1일부터 저는 닷슬래시대시에 함께하였고 처음으로 다른 서버 개발자분들과 작업을 진행할 수 있었습니다. 그리고 12월까지 두 달간 작업을 진행하며 함께 일을 하는 즐거움과 제 자신에 대한 너무 아쉬운 부분들에 대해 알게 되었습니다. 항상 혼자서 작업하던 저는 함께 일하는 다른 분들을 배려하지 않는 코드를 짜고 있었고, 계속 긴장을 하고 있어서 그런지 조금만 집중해서 보면 쉽게 알 수 있는 문제들을 계속 놓치고 있었습니다. 때문에 저는 리더님과의 면담으로 알게 된 것들, 작업하며 스스로 깨달은 부분들을 수정하며 개발 능력을 크게 키울 수 있는 2023년을 보내려 합니다.  2022년 내가 한 것들: 1. Blog 글 쓰기: 블로그를 한번 이전하면서 이전에 썼던 것들도 있었겠지만 2022년에 쓴 블로그는 다음과 같습니다.  2022년 03월 15일 - AWS Lambda에 Bootpay연동하기 - 결제 검증 2022년 03월 30일 - FastAPI에 2개 이상의 DB연동하기 2022년 04월 04일 - Amazon EventBridge로 특정시간에 자동으로 카운트해보기 -1 2022년 04월 06일 - Amazon EventBridge로 특정시간에 자동으로 카운트해보기 -2 2022년 04월 10일 - jQuery 정규식 [id^=] 사용해보기 2022년 04월 19일 - 알아두면 쓸모있는 MySQL 명령어 모음 2022년 04월 28일 - MySQL offset 활용 2022년 05월 04일 - 자바스크립트 예쁜 모달창 만들기 2022년 05월 09일 - jQuery로 버튼 클릭 이벤트 만들기 2022년 05월 17일 - form-data? x-www-form-urlencoded? raw? 2022년 06월 04일 - (문제해결)ERROR 1227 (42000) at line 18 - Access denied; you need (at least one of) the SUPER privilege(s) for this operation 2022년 06월 16일 - Python GIL, Global interpreter Lock 2022년 07월 01일 - (문제해결)You do not have the SUPER privilege and binary logging is enabled (you might want to use the less safe log_bin_trust_function_creators variable) 2022년 07월 22일 - 신입 백앤드 개발자(나)를 위한 면접 질문 정리 - 네트워크, 운영체제 2022년 07월 28일 - 신입 백앤드 개발자(나)를 위한 면접 질문 정리 - 데이터베이스 2022년 08월 13일 - 신입 백앤드 개발자(나)를 위한 면접 질문 정리 - 기타(공통, 인프라/클라우드(AWS), 컨테이너) 2022년 08월 19일 - VPC내의 AWS Lambda의 인터넷 접속하기 2022년 08월 31일 - ALB(Application Load Balancer)에서 URL 기반 라우팅 2022년 09월 25일 - 스트리밍 서비스와 AWS Media Services 2022년 12월 03일 - What is Apache Kafka?그동안 작성한 포스트를 정리해 보면서, 보통 달에 한개 정도의 포스트이지만 그래도 꾸준히 쓴 것과 포스팅 능력이 조금 늘은 것에 뿌듯함을 느꼈습니다. 😆2023년에는 단순히 문서에 나와 있는 기술을 따라한 포스트보다는 저만의 글을 쓰는 것을 목표로 하려고 합니다.  2. 처음으로 사용한 기술들: 1. FastAPI: 2021년 후반에 당시 대부분의 서버 개발은 Flask 혹은 AWS Lambda와 같은 서버리스 환경에서만 개발을 주로 했던것 같습니다. 1월 쯔음 그 당시 외부 개발자로 계시던 시니어 개발자분이 계셨는데, 저에게 FastAPI를 추천해주셨습니다. swagger를 자동으로 생성해주는 것과 너무 잘 되어져 있는 문서가 정말로 매력적이었기 때문에(물론, 훨씬 더 많은 매력적인 요소들이 있었습니다. ) 이 때 처음으로 FastAPI를 사용해보았습니다. FastAPI에 2개 이상의 DB연동하기 2. Amazon EventBridge: 어쩌다 보니 AWS Lambda에 트리거를 걸 일이 발생하였습니다. AWS Lambda는 실시간으로 코드를 실행할 수는 있으나, 필요시에만 함수를 실행합니다. 그래서 Amazon EventBridge를 사용하여 크론(Cron) 표현식으로 특정 시간마다 Lambda에 트리거를 걸어주었습니다. Amazon EventBridge로 특정시간에 자동으로 카운트해보기 -1Amazon EventBridge로 특정시간에 자동으로 카운트해보기 -2 3. MongoDB: MySQL을 주로 사용하다 처음으로 NoSQL인 MongoDB를 사용했습니다. MySQL의 Table은 정형화되어 사전에 정의된 필드들만 저장을 할 수 있던 반면에 MongoDB는 Json과 비슷한 형태의 Document로 저장을 했습니다. 규정된 스키마가 없었기에 저장되는 필드는 계속 달라질 수 있었고, 그로 인해 MySQL의 Join과 같은 큰 연산을 쓸 경우는 거의 없었지만 전에 있던 필드의 정보가 변경될 시 데이터 마이그레이션을 해야 할 가능성이 있다는 것을 알 수 있었습니다. 4. Git: 전에 재직하던 회사에서는 혼자서 작업하는 경우가 대다수였기 때문에, Git을 제대로 사용할 경우가 거의 없었습니다. 기껏 해봤자 Repository에 add, commit, push가 다였었는데, 이번 닷슬래시대시에 입사하고 처음으로 다른 개발자분들과 소통하며 작업을 진행하다 보니, Git의 중요성을 크게 알게 되었습니다. 브랜치를 생성/관리/삭제, Pull requests, Pull 대신 fetch와 merge, glola, add 대신 add -p 등등. . 정말 많은 것에 대해 가르쳐 주셨고 아직도 배우고 있는 중입니다. 5. 편리함을 위한 앱들: Mac에서 버전 관리를 위한 asdf, 편한 메모를 위한 Obsician, 검색을 도와주는 Alfred(primmadonna님이 이걸 쓰면 인생이 달라질 거라고 했던… 현재 정말 유용하게 잘 쓰고 있습니다. 👍) 등이 있습니다.  2022년 또 무슨 일이 있었나??: 제 머릿 속의 기억만 의존 하다 보니 쉽지는 않지만 정리가 되는 대로 꾸준히 이곳에 작성을 해보려 합니다. 전체적으로 바쁨과 쉼이 공존한 한 해였습니다. 이전에 재직 중이던 회사에서 퇴직하기까지 바쁘게 지내다가 퇴사 후 두 달 동안 휴식을 가졌고, 다시 취업 준비를 하다가 현재 재직 중인 회사에서 다시 바쁘게 지내기까지. . 저는 혼자서 곳곳을 돌아다닐 정도로 여행을 정말 좋아하는데, 코로나19 이후로 단 한 번도 여행을 가지 않았던 것 같습니다. 굳이 여행이라 생각한다면 기껏 해봐야 1월에 갔었던 춘천, 여름에 갔었던 가평과 캐리비안베이가 다였던 것 같습니다. 코로나가 이제는 독감처럼 인식된 지금, 2023년에는 시간만 된다면 가까운 곳이라도 그동안 못 갔었던 여행을 다녀와보려 합니다. 드디어 제 블로그에 검색을 위한 Google Search와 광고를 위한 애드센스를 붙였습니다. 하필 회고록을 적고 있는 지금 애드센스 승인이 실패한 메일을 받았습니다,, 빠르게 다시 붙일 수 있도록 문제점을 찾고 승인을 받으려 합니다.  새로바꾼 블로그 테마 command+shift+R하면 바뀜  끝맺음 2022년은 전체적으로 제 자신과 주위를 많이 둘러볼 수 있었던 한 해가 되었던 것 같습니다. 제 자신을 평가할 수 있는 여러 기회가 있었고(실망스러운 부분과 좋았던 부분), 이를 통해 2023년에는 깨달은 부분에 대해서만이라도 노력한다면 꽤나 괜찮은 해가 될 수 있을 것 같기도 합니다. 처음으로 회고록을 작성해 보면서 평소 하는 것들에 대한 기억의 중요성을 절실히 느끼고 있습니다. 2022년에 정말 많은 일들이 있었을 테지만 기억을 저장해 두지 않아서 온전히 제 기억으로만 여러 가지를 적으려 하니 많은 것을 적지 못하는 것이 조금 아쉬웠습니다. 그래도 간단하게나마 제가 했던 것들에 대해 정리를 해보면서, 2023년에는 어떻게 보내고 싶다는 가닥이 조금은 선명하게 잡혔습니다.  나만의 포스트를 쓰기 일을 하며 아쉬웠던 저의 모습들을 하나씩 고쳐가며 발전하는 것(계속 나오겠지만) 새로운 것들을 정리하여 도전해보기(activity한 것들, 새로운 기술 공부) 기억을 위한 평소 뭐든 메모하는 습관을 가지기 꾸준히 운동하기(매년 있는 목표) 페이스 조절을 위한 여행 기초적인 실력 정리하고 키우기(with a clean code) "
    }, {
    "id": 9,
    "url": "http://localhost:4000/kafka/",
    "title": "What is Apache Kafka?",
    "body": "2022/12/10 -  💡 Intro: Kafka는 많은 서비스에서 백엔드로 사용하고 있습니다. 저는 Kafka의 ‘K’ 정도만 알고 있기 때문에, 오늘은 Kafka의 개념과 기본 구조에 대해서 알아보려고 합니다.  🔎 Kafka의 탄생: 링크드인은 사이트가 급속도로 성장하면서 기존의 End to End 연결 방식이었던 아키텍처로는 복잡도, 데이터 파이프라인 관리 등의 어려움 때문에 새로운 아키텍처가 필요로 해졌습니다. 이를 해결하기 위해 링크드인은 Kafka라는 메시징 분산 스트리밍 플랫폼을 개발하게 되었습니다.  당시 링크드인의 요구사항은 1. 높은 처리량으로 데이터를 실시간으로 처리 가능 해야 하며, 2. 메시지의 영속성을 보장해 주고, 3. Scale out이 용이 해야 한다 등이 있었습니다. 하지만 당시의 제품들은 높은 처리량이 우선 순위였던 링크드인의 요구사항보다 트랜젝션의 관리가 너무 오버스펙이거나, 메시지 큐로 데이터를 쌓긴 하지만 장시간 쌓이는 것은 고려하지 않는 등의 문제로 충족시키지 못했습니다. 당시 링크드인의 자세한 요구사항은 🌎한빛미디어-링크드인은 왜 카프카를 만들었나을 통해 확인 하실 수 있습니다.  What is Apache Kafka?: Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications. - 출처: Apache Kafka Apache Kafka의 공식사이트에서는 Apache Kafka란 수천 개의 기업이 고성능 데이터 파이프라인, 스트리밍 분석, 데이터 통합, 미션 크리티컬 애플리케이션을 위해 사용하는 오픈 소스 분산 이벤트 스트리밍 플랫폼이라고 설명합니다. 즉, Kafka는 데이터를 생성하는 어플리케이션과 데이터를 소비하는 어플리케이션 간의 중재자 역할을 함으로써 데이터의 전송 제어, 처리, 관리 역할을 하며 Publish-Subscribe 모델을 구현한 분산 메시징 시스템입니다.  Message Queue란? 프로그램 간 데이터를 교환할 때 사용하는 통신 방법 중 하나이며 🌎Message-Oriented Middleware의 구현을 의미합니다.  Apache Kafka의 특징:  Kafka의 topic에 여러 프로듀서가 동시에 메시지를 전송할 수 있으며, Kafka topic의 메시지를 여러 컨슈머들이 동시에 읽어 갈 수 있습니다. 때문에, 다중 프로듀서/컨슈머의 지원으로 하나의 Kafka 시스템을 통해 다양한 애플리케이션이 데이터를 주고 받을 수 있습니다.  Kafka는 프로듀서가 생성한 메시지를 브로커가 위치한 서버의 파일 시스템에 저장할 수 있기 때문에, 데이터의 영속성을 보장해 줍니다.  Scale out 즉, 확장성이 용이합니다. 프로듀서, 컨슈머, 브로커등을 운영중에 추가할 수 있으며 예를 들어 초창기에 적은 수의 브로커들로 클러스터를 운영하다가 시스템 트래픽이 높아지면 브로커를 추가해서 클러스터를 확장할 수 있습니다.  Kafka는 Push가 아닌 컨슈머가 브로커에게서 메시지를 가져오는 Pull방식이기 때문에 컨슈머의 처리량을 브로커가 고민할 필요가 없습니다. 즉, 컨슈머는 자신이 처리할 수 있는 만큼의 메시지만 브로커에게서 가져가면 되기 때문에 최적의 메시지처리 성능을 가질 수 있습니다. Apache Kafka의 아키텍처: 이미지 1. Kafka 아키텍처(출처: Developer. holee Blog) Kafka는 Publish-Subscribe 모델을 기반으로 동작하며, 위 이미와 같이 크게 producer, consumer, broker, Zookeeper로 구성됩니다. Producer는 특정 topic의 메시지를 생성한 뒤 해당 메시지를 broker에 전달합니다. Broker가 전달받은 메시지를 topic별로(Foo, bar) 분류하여 쌓아놓으면, 해당 topic을 구독하는 consumer들이 메시지를 가져가서 처리합니다. 클러스터 내의 broker에 대한 분산 처리는 이미지 1. Kafka 아키텍처와 같이 🌎Apache ZooKeeper가 담당합니다.  여담으로, Apache Kafka에 대한 자료를 찾다가 Apache Kafka에서 Zookeeper을 제거한다는 소식이 있다는 것을 알게되었습니다. 🌎아파치 카프카에서 ‘주키퍼’ 빠진다…”내부 메타데이터 프로토콜로 대체” 조금 더 깊이 들어 가기 전, Apache Kafka의 기본 개념은 아래와 같습니다.  프로듀서(Producer) : 데이터를 발생시키고 Kafka 클러스터에 적재하는 프로세스입니다.  카프카 클러스터(Kafka Cluster) : 카프카 클러스터는 카프카 서버로 이루어진 클러스터를 말하며, 카프카 클러스터를 이루는 각 요소는 다음과 같습니다.  토픽(Topic) : Kafka 클러스터에 데이터를 관리할 시 그 기준이 되는 개념입니다. 토픽은 Kafka 클러스터에서 여러개 만들 수 있으며 하나의 토픽은 1개 이상의 파티션으로 구성되어 있습니다.  브로커(Broker) : Broker는 실행 된 Kafka serve 중 1대를 뜻합니다.  파티션(Partition) : 각 토픽 당 데이터를 분산 처리하는 단위입니다. Kafka에서는 토픽 안에 파티션을 나누어 그 수 대로 데이터를 분산처리합니다.  Offset : 파티션 내의 각 레코드를 고유하게 식별하는 순차적인 ID를 뜻합니다.  주키퍼(Zookeeper) : 주키퍼는 분산 코디네이션 시스템입니다. Kafka 브로커를 하나의 클러스터로 코디네이팅하는 역할을 합니다.  컨슈머 그룹(Consumer Group) : 컨슈머의 집합을 구성하는 단위입니다. 카프카에서는 컨슈머 그룹으로서 데이터를 처리하며 컨슈머 그룹 안의 컨슈머 수만큼 파티션의 데이터를 분산처리하게 됩니다.  Broker Partition Replication : Replication은 각 Topic의 Partition들을 Kafka Cluster내의 다른 Broker들로 복제하는 것을 말하며 Topic생성 시 Replication의 수를 지정할 수 있습니다. 생성된 Replication은 Leader와 Follower로 나뉘어 ISR(In Sync Replica)이라는 일종의 Replication Group을 형성하여 관리됩니다.  ISR(In Sync Replica) : Reader, Follower 파티션이 모두 동기화된 상태를 말합니다. Kafka 아키텍처의 구성요소: 1. Topic과 Partition: 이미지 2. Kafka Topic(출처: Apache Kafka) 하나의 topic이 3개의 partition에 분산되어 순차적으로 저장되어지는데, 이 때 각 partition은 0부터 1씩 증가하는 offset 값(고유 ID)을 메시지에 부여합니다. offset 값은 partition마다 별도로 관리되기 때문에 topic내에서 메시지를 식별할 때는 partition 번호와 offset 값을 함께 사용합니다.  2. Broker: Kafka Cluster는 여러대의 broker(server)로 구성되어져 있습니다. 보통 3개 이상의 broker로 클러스터를 운영하며, 각각의 broker는 고유한 id 값으로 구분되어집니다.  이미지 3. Replication(파란색이 리더) Replication은 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도 데이터를 유실하지 않고 안전 하게 하기 위해 사용됩니다. Kafka의 데이터 복제는 파티션 단위로 이루어집니다. 위와 같이 3개의 broker가 있을 때, 복제된 파티션은 1개의 리더(leader)와 N-1개의 팔로워(follower)로 구성됩니다. 각각의 팔로워는 리더의 오프셋을 확인하고, 현재 자신이 가지고 있는 오프셋과 차이가 나는 경우 리더로부터 데이터를 가져와서 자신의 파티션에 저장합니다. 파티션의 데이터가 복제되므로 복제 개수만큼의비용이 발생하게 되지만 데이터의 안전이 보장되기 때문에 이러한 비용을 감수하고 복제를 수행한다고 합니다.  이미지 4. Replication-error 여기서 갑자기 리더의 broker에 error가 발생하게 된다면, 팔로워 파티션 중 하나가 리더 파티션의 지위를 넘겨받게 됩니다. 이를 통해 데이터가 유실되지 않고 데이터의 안전성을 보장할 수 있게 됩니다.  3. Consumers와 Consumer Groups: 이미지 5. Consumer Groups Kafka의 파티션은 consumer group당 오로지 하나의 컨슈머의 접근만을 허용합니다. 따라서 동일한 consumer group에 속하는 컨슈머끼리는 동일한 파티션에 접근할 수 없습니다. 만일, 컨슈머가 추가/제거되면 추가/제거된 컨슈머가 속한 consumer group 내의 컨슈머들의 파티션 재분배가 발생하고, broker가 추가/제거되면 전체 consumer group에서 파티션 재분배가 발생합니다. 위의 그림과 같이 consumer group을 구성하는 컨슈머의 수가 파티션의 수보다 작으면 하나의 컨슈머가 여러 개의 파티션을 소유할 수 있습니다. 하지만, 반대로 컨슈머의 수가 파티션의 수보다 많다면 몇몇 컨슈머는 수행 하는 것이 없이 놀고 있을 수 있습니다. 때문에 파티션 개수와 컨슈머 수의 적절한 설정이 필요합니다.   끝맺음 Apache Kafka는 근래에 가졌던 가장 최고의 관심사 였는데, 오늘 공부를 해보면서 이론만으로는 부족하다는 느낌을 절실히 경험했습니다. 다음 포스팅에는 이론이 아닌 실전편의 Kafka를 포스팅 해보려고 합니다! 공부하면서 포스팅을 하다보니 많은 부족한 점이 있을 수 있습니다. 혹여나 내용에 이상이 있다면 댓글로 알려주시면 감사드립니다! 😀👍 [참고자료]  Apache Kafka Docs 서해바다 - Apache Kafka 기본 개념 총정리 Message Oriented Middleware 링크드인은 왜 Kafka를 만들었나 Developer. holee - Apache Kafka https://zookeeper. apache. org/"
    }, {
    "id": 10,
    "url": "http://localhost:4000/diary/",
    "title": "My Diary",
    "body": "2022/09/25 -  🔮 대충 다이어리용 끄적임: 🗓 2022-09-25 15:55:20: 커뮤니티에서 IT 엔지니어를 위한 네트워크 입문 이라는 네트워크에 대한 책을 추천을 받았습니다. 사알짝 늦은 감이 있나 싶었지만, 제가 보기에 저는 아직 네트워크에 네ㅌ… 정도(?)만을 아는 것 같기도 하고 다시 기초를 탄탄히 다져보면 좋을 것 같은 생각에 곧바로 구매했습니다. 이틀 전에 구매를 하고 오늘 오전에 받아서 오늘부터 정독해 보려고 합니다. (지금 하고 있는 것들이 너무 많아서 조금씩이라도 꾸준히 정독하려고 합니다. 🥲)  🗓 2022-09-28 13:55:33: 서점을 돌아다니던 도중,,,, 클라우드 AWS 자격증으로 시작하기 라는 책을 봤습니다. 대충 내용을 훑어보니, AWS Cloud Practitioner 자격증과 AWS Solutions Architect 자격증에 내용을 맞춰서 클로우드에 대해 설명해 주고 있길래 일단 읽어 보자는 마음에 구매를 먼저 했습니다. 아직 다 못 읽어본 책도 있는데 이것도 틈틈이 읽어야겠습니다. ;ㅅ; 이러다가 책 수집하는 게 취미가 될 것 같네요.  추가 - 리뷰를 보니 번역상의 오류가 조금씩 있다고 하네요. (예를 들어, ElasticCache -&gt; ElastiCache) 또한 문제의 지문 번역이 애매한 것들도 있다고 하군요. 전 그래도 이런 느낌의 AWS의 책은 처음 보아서 그런지 좀 더 다양한 자격증과 풍부한 내용이 더해진다면 더 좋을 것 같습니다! 계속 천천히 읽어보겠습니다. 😊  🗓 2022-10-01 17:05:23: 오늘 파이콘 행사에 참여했습니다. 원티드의 FastAPI, GIL(Global Interpreter Lock), 파이썬 서버리스 웹서비스 등의 여러 강의와 오후에는 python을 사용하는(파이콘 후원 업체) 여러 기업의 채용 및 회사 설명에 대해 들었습니다. 영상 재생인데다, 15~40분 내로 강연이 끝나야 하다 보니 강연에 대해서는 조금 아쉬웠지만, 그래도 오후의 채용 설명에서는 정말 좋은 경험이 되었던것 같습니다. 크게 기억에 남았던 것은 두 가지가 있었는데, 첫 번째로는 🌏Soomgo의 채용 프로그램과 애자일 위주로 돌아가는 개발 프로세스였는데, 잘 모른다고 하니 끝나고 나서 하나하나 다 설명해 주시고 끝나고 나서도 절 따로 불러주셔서 부족한 부분에 대해 친절하게 다 설명해 주셨습니다…😀 두 번째로 🌏닷슬래시대시라는 회사의 조은우 개발자님 이셨는데, 같은 오픈 채팅방에 계신 분이셨습니다. 제 첫 회사가 스타트업이었고 서버 개발자가 저 혼자였던 만큼, 많은 부분에서 공감해주시고 이해해 주셨습니다. 😭 또한 서비스 아키텍처 구성, 시스템 설명까지 너무 친절하게 설명해 주셔서 정말 감사했었습니다. 또한 조은우 개발자님께서 함께 있었던 다른 주니어 개발자분들과도 대화를 잘 이끌어서 주셔서 짧지만 알차게 여러 이야기에 대해 들을 수 있었습니다. 오늘 파이콘 참가하신 많은 분들 너무 수고하셨고, 좋은 기회를 주신 파이콘 기획자님들 정말 감사합니다!(추가로, 파이콘 행사 구성품이 꽤나 알찼습니다. 옷, 피규어, 기타 물품들…)  🗓 2023-01-11 21:03:55: 리더님과의 원온원 중 리더님이 저에게 이런 말씀을 해주셨습니다.  다른 기술들은 잘 몰라도 전혀 이상하지 않습니다. 필요한 부분에 대해 학습하며 실력을 키우면 되니깐요. 하지만 개발자로써 코딩은 잘해야 합니다.  저는 이 말에 정말 공감했습니다. 결국 백앤드 개발자에게 가장 기본이면서 제일 중요한 것은 코딩 실력입니다. kafka, cloud, k8s 등 많은 기술이 있지만 요즘은 Document가 너무 잘 되어 있기 때문에 열심히 배우면 충분히 할 수 있습니다. 하지만 코딩은 결국 누군가와 함께 하기 위한 좋은 코드를 개발해야 합니다. 혼자서 여러 알고리즘과 모듈, 프레임워크 등 많은 공부를 했다고 해도 금방할 수 있는 것이 아니기 때문에 더욱 꾸준한 노력이 필요합니다. 최근 1년 동안 코딩보다 클라우드, DB 등 다른 것에 더욱 초점을 맞추다가 근래 다시 코딩에만 집중하며 작업을 하다 보니 제 코딩 실력이 부족하다는 것을 뼈저리게 느끼고 있었습니다. 또한 누군가 제 코딩을 보며 함께 코딩을 한다는 버릇을 잘 안 들이다 보니, 코드에 대한 배려심도 부족했었습니다. 그래서 리더님은 로버트C. 마틴(엉클 밥)의 🌏Clean Code라는 책을 추천해 주셨습니다. Clean Code는 제목 그대로 깨끗한 코드를 작성하기 위한 방법에 대해 설명해 줍니다. 또한 제3자가 보기에도 읽기 쉽고 고치기 쉬운 코드를 만드는 것을 중요하게 생각합니다. 이후에 책을 읽으면서 정말 좋은 부분들이 있다면 Clean Code에 대해 정리한 부분을 포스팅을 해보려 합니다.  "
    }, {
    "id": 11,
    "url": "http://localhost:4000/streaming/",
    "title": "스트리밍 서비스와 AWS Media Services",
    "body": "2022/09/15 -  💡 Intro: Youtube를 보다가 정말 정말 갑자기 스트리밍 서비스에 대해 궁금해졌습니다. 단순히 CDN(Content Delivery Network)을 사용한다 정도만 알고 있었는데, 조금 자세하게 공부를 해보려 합니다.  🔎 스트리밍(Streaming) 이란?: 스트리밍 서비스란 인터넷에서 음성,미디어 컨텐츠를 실시간으로 재생하는 방식을 뜻합니다. 이러한 스트리밍 서비스에는 Progressive download, RTSP, RTMP 스트리밍, Adaptive HTTP Streaming 등 여러가지 프로토콜이 있습니다. 프로그레시브 다운로드(Progressive Download) : 웹 서버로부터 동영상을 다운로드하면서 파일이 도착하는 대로 재생해주는 방식  웹서버에 파일을 올려놓고 URL주소를 player에 링크만 걸면 되므로 사용이 편리함 동영상이 끊김없이 재생되기 위해서는 네트워크 속도가 동영상의 데이터 레이트 보다 높아야 함 내컴퓨터로 파일을 다운로드 하는 것이기 때문에 보안에 문제가 있어 유료 비디오 서비스를 위해서는 사용할 수 없음 데이터 소비가 사용자가 보는 만큼이 아니라 다운로드 된 만큼 소비RTSP/RTMP 스트리밍(RSTP/RTMP Streaming) : 프로그레시브 다운로드 방식과는 달리 사용자가 현재 시청하고 있는 비디오 프레임만을 전송해주는 방식  유저가 보는 장면을 찾아 그 프레임부터 시작이 되며, 지나간 프레임 데이터는 자동 삭제되는 방식 다운로드가 없어 보안에 문제가 상대적으로 적음 필요한 부분만 전송하므로 bandwidth과 데이터 소비에 대해 효율성이 좋음Adaptive HTTP Streaming : 미디어 컨텐츠를 동영상 컨텐츠 하나로 저장하는게 아니라 잘게 쪼개서 저장하는 방식. 대표적으로 Apple에서 만든 HLS(HTTP Live Streaming) 가 있음 HLS(HTTP Live Streaming) : HTTP 프로토콜을 사용하는 실시간 스트리밍 방식으로, 스트리밍 데이터를 m3u8의 확장자를 가진 재생목록 파일과 잘게 쪼갠 다수의 ts파일을 http을 통해 전송하는 방식  HTTP를 프로토콜을 사용하며 HTML5 및 미디어 소스 확장으로 모든 장치의 호환성이 높으므로 도입 비용을 절약할 수 있음 적응형 스트리밍 방식으로 인터넷 속도에 따른 품질이 동적으로 조정됨 일반적인 프로토콜은 UDP형식으로 만들어진데 반해, HLS는 TCP형식이라서 라이브 스트림일 때 Delay 문제가 있음 이미지 1. HLS의 구성(출처: Apple Documentation Archive)  유튜브에서 원래 프로그레시브 다운로드 방식을 사용하다가 현재는 Adaptive HTTP Streaming 방식을 사용하고 있다고 합니다.  🔎 AWS Media Services를 통한 라이브 및 온디맨드 동영상 워크플로 구성 및 배포하기: 이를 이제 AWS에서 어떻게 배포할 수 있을지에 대해서 찾아보았는데… 🌏AWS Builders 온라인 2021에서 김영진님께서 이 내용을 다루어주셨더라구요!(AWS…. . 너란 클라우드. . ) 서비스를 너무 잘 소개해 주셔서 아래에 Youtube 영상 주소를 올리겠습니다. 이미지를 클릭하시면 해당 영상으로 이동됩니다.  클릭시 Youtube로 이동됨 영상을 시청하시면 Live Streaming과 VOD(Video On Demand) streaming 두 가지다 개념부터 워크플로, Demo 버전을 만드는 것까지 자세하게 설명하고 있습니다. 그래서 저는 영상에 나오는 기본적인 AWS 서비스들에 대해서 따로 정리해 보려고 합니다.  이미지 2. AWS 미디어 서비스를 이용한 워크플로우(출처: AWS Youtube) 🔎 영상속 AWS 서비스 정리: 🌎 AWS Media Services: 🌏AWS Media Services는 클라우드에서 안정적인 브로드캐스트 품질의 비디오 워크플로를 손쉽게 구축할 수 있게 해주는 완전 관리형 서비스 패밀리입니다. 웹을 들어간 후, 상단 메뉴에 있는 서비스를 클릭하면 다양한 제품들을 확인할 수 있습니다.  AWS Elemental MediaLive: AWS ElementalMediaLive는 브로드캐스트 및 스트리밍 전송을 위한 라이브 출력을 생성할 수 있는 실시간 비디오 서비스입니다. 이 서비스를 사용하면 텔레비전과 인터넷 연결 멀티스크린 디바이스(커넥티드 TV, 태블릿, 스마트폰, 셋톱 박스 등)로 전송할 수 있는 고품질 비디오 스트림을 생성할 수 있습니다. - 출처: AWS Docs AWS Elemental MediaLive는 Live 비디오 스트림을 실시간으로 인코딩하고 배포하는 서비스입니다. 쉽게 설명하자면, 고해상도의 입력신호를 적합한 화질로 변환해줍니다.  AWS Elemental MediaPackage: MediaPackage는 AWS 클라우드에서 실행되는 적시 비디오 패키징 및 오리지네이션 서비스입니다. MediaPackage를 사용하면 매우 안전하고 확장 가능하며 신뢰할 수 있는 비디오 스트림을 다양한 재생 디바이스 및 CDN(콘텐츠 전송 네트워크, 여기서는 Amazon CloudFront)에 전달할 수 있습니다. - 출처: AWS - MediaPackage MediaPackage는 단일 비디오 입력으로부터 커넥티드 TV, 휴대폰, 컴퓨터, 태블릿 및 게임 콘솔에 맞는 형식으로 비디오 스트림을 생성해줍니다. 또한, 인기 있는 비디오 기능(다시 시작, 정지, 되감기 등)을 손쉽게 구현할 수 있고 DRM(Digital Rights Management)을 사용해 콘텐츠를 보호해준다고 합니다.  DRM(Digital Right Management) 이란 정보보호 기술 중 하나로 암호화 기술을 이용해서 비허가 사용자로부터 디지털 컨텐츠를 보호하게 하는 기술을 말합니다. AWS Elemental MediaPackage는 라이브 패키징과 VOD 패키징이라는 두 가지 요금 모델을 제공합니다. 라이브 패키징의 경우 채널로 수집된 비디오의 양(GB로 측정)과 채널에 대해 오리지네이션 및 패키징된 콘텐츠의 양(GB로 측정)에 따라 요금이 부과됩니다. VOD 패키징을 사용하면 VOD 패키징 그룹에서 오리지네이션 및 패키징된 비디오 컨텐츠의 양(GB로 측정)에 따라 요금이 청구됩니다. 자세한 요금 사항은 🌏AWS Elemental MediaPackage 요금을 확인해 주세요.  AWS Elemental MediaStore: AWS Elemental MediaStore는 미디어에 최적화된 AWS 스토리지 서비스입니다. 이는 라이브 스트리밍 비디오 콘텐츠를 전송하는 데 필요한 성능, 일관성 및 짧은 지연 시간을 제공합니다. AWS Elemental MediaStore는 비디오 워크플로에서 오리진 스토어의 역할을 합니다. 이 서비스의 뛰어난 성능은 비용 효율적인 장기 스토리지와 결합되어 가장 까다로운 미디어 전송 워크로드의 요건을 충족합니다. - 출처: AWS - MediaStore Docs를 읽고나면 S3와의 차이점에 대해 궁금하실텐데, Docs에 적힌데로 MediaStore는 미디어에 최적화된 AWS 스토리지 서비스입니다. cacheing layer가 있으며 S3보다 latency가 짧기 때문에 라이브 비디오에는 MediaStore를, VOD(Video On Demand)에는 S3를 사용한다고 합니다. AWS Elemental MediaStore는 콘텐츠가 서비스에 도달할 때 GB당 미디어 최적화 수집 비용이 부과되고, 라이브 및 VOD 전송을 위해 서비스에 유지하는 콘텐츠에 대해 GB당 콘텐츠 스토리지 비용이 부과됩니다. 자세한 요금 사항은 🌏AWS Elemental MediaStore 요금을 확인해 주세요.  AWS Elemental MediaTailor: AWS Elemental MediaTailor는 비디오 공급자가 브로드캐스트 수준의 서비스 품질을 떨어뜨리지 않고 비디오 스트림에 개별적으로 타겟 광고를 삽입할 수 있는 서비스입니다. - 출처: AWS - MediaStore 이미지 3. AWS Elemental MediaTailor 작동 방식(출처: AWS - MediaTailor) 즉, AWS Elemental MediaTailor란 수익 창출을 위한 광고 삽입 서비스입니다. MediaTailor는 클라이언트 측과 서버 측 광고 전달 지표 둘 다를 기준으로 자동화된 보고서를 제공해주기 때문에, 광고 노출 수와 시청자 동작을 정확하게 측정할 수 있다고 합니다.  AWS Elemental MediaConvert: AWS Elemental MediaConvert 콘텐츠 소유자와 배포업체에게 모든 규모의 미디어 라이브러리에 대한 확장 가능한 비디오 처리를 제공하는 파일 기반 비디오 처리 서비스입니다. MediaConvert 에서는 다음과 같은 프리미엄 콘텐츠 경험을 지원하는 고급 기능을 제공합니다. - 출처: AWS Docs 이미지 4. AWS Elemental MediaConvert 작동 방식(출처: AWS - MediaConvert) 즉, 디바이스로 전달할 영상 파일을 인코딩 해주는 역할을 해주고 있습니다. 요금은 베이직 티어와 프로페셔널 티어로 나뉘어져 있고, 프로페셔널이 베이직 보다 1. 5배 이상 비싸기 때문에 제공하는 서비스에 따라서 잘 선택하셔야 할 것 같습니다. 🤔 자세한 사항은 🌏AWS Elemental MediaConvert 요금에서 확인 하시면 됩니다.  🌎 Other AWS Services: Amazon S3: Amazon Simple Storage Service(Amazon S3)는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 서비스입니다. 모든 규모와 업종의 고객은 Amazon S3를 사용하여 데이터 레이크, 웹 사이트, 모바일 애플리케이션, 백업 및 복원, 아카이브, 엔터프라이즈 애플리케이션, IoT 디바이스, 빅 데이터 분석 등 다양한 사용 사례에서 원하는 양의 데이터를 저장하고 보호할 수 있습니다. Amazon S3는 특정 비즈니스, 조직 및 규정 준수 요구 사항에 맞게 데이터에 대한 액세스를 최적화, 구조화 및 구성할 수 있는 관리 기능을 제공합니다. - 출처: AWS Docs Amazon S3는 데이터를 저장하고 검색할 수 있는 간단한 API를 제공하는 완전 관리형 스토리지 서비스입니다. 즉, Amazon S3에 저장하는 데이터는 특정 서버와 관련이 없으므로 사용자가 인프라를 직접 관리할 필요가 없습니다. 또한 일반적인 파일 서버는 사용자 트래픽이 증가하면 스토리지 증설 작업을 해야하지만 S3는 시스템 적으로 트래픽 증가에 대한 처리를 미리 해두었기 때문에 파일 서버 관리자는 별도의 처리를 해주지 않아도 됩니다. bucket(최상위 디렉토리)이라는 폴더에 Object(S3에 저장되는 데이터)인 파일을 저장하여 사용합니다. 🌏Amazon S3 Simple Storage Service 요금 - AWS이곳에서 요금에 대한 정보를 확인하실 수 있습니다.  AWS Step Functions: AWS Step Functions은 시각적 워크플로우를 사용해 분산 애플리케이션 및 마이크로서비스의 구성 요소를 손쉽게 조정하도록 해주는 웹 서비스입니다. 각각 기능 또는 작업을 수행하는 개별 구성 요소를 사용하여 애플리케이션을 구축하면 애플리케이션을 빠르게 확장하거나 변경할 수 있습니다. - 출처: AWS Docs 쉽게 설명하면 AWS의 여러 컴퓨팅 자원들의 수행 순서를 시각적으로 설정할 수 있는 서비스입니다. 또한, AWS Lambda같은 경우는 상태 값이 없어서 데이터를 확인하려면 DB에서 데이터를 확인했는데, Step Functions을 활용해서 Lambda 함수를 각 단계에 설정할 수 있다고 합니다. Step Function은 진행중인 단계에 맞게 처리할 데이터를 Lambda 함수에 보내주게할 수 있는데, 이렇게 하면 원하는 상태 정보를 알 수 있게 되고 각각의 워크플로우들을 한눈에 관리할 수 있다고 합니다. (이전에 처음으로 Lambda를 이용할 때는 Step Functions대해 몰랐었었는데, 한번 써볼 기회가 생겼으면 좋겠네요!😃) Amazon CloudFront: Amazon CloudFront는 . html, . css, . js 및 이미지 파일과 같은 정적 및 동적 웹 콘텐츠를 사용자에게 더 빨리 배포하도록 지원하는 웹 서비스입니다. CloudFront는 엣지 로케이션이라고 하는 데이터 센터의 전 세계 네트워크를 통해 콘텐츠를 제공합니다. CloudFront를 통해 서비스하는 콘텐츠를 사용자가 요청하면 지연 시간이 가장 낮은 엣지 로케이션으로 요청이 라우팅되므로 가능한 최고의 성능으로 콘텐츠가 제공됩니다. - 출처: AWS Docs 즉, CloudFront는 AWS에서 제공하는 CDN 서비스 입니다. 사용자로부터 요청이 발생하면 요청이 발생한 Edge Server(컨텐츠들이 캐시에 보관되어지는 장소) 은 요청이 발생한 데이터에 대하여 캐싱 여부를 확인합니다. 그리고 캐싱 데이터가 존재하면 사용자에 요청에 맞게 응답하고 존재하지 않으면 Origin Server(원본 데이터를 가지고 있는 서버, S3/Ec2 instance) 로 요청합니다. 요청 받은 데이터에 대해 Origin Server로부터 전달 받은 Edge Server는 캐싱 데이터를 생성하고 사용자에게 응답하게 됩니다.  CDN(Content Delivery Network, 콘텐츠 전송 네트워크) 이란? 지리적 제약 없이 전 세계 사용자에게 빠르고 안전하게 콘텐츠를 전송할 수 있는 콘텐츠 전송 기술입니다.  이미지 5. CloudFront에서 사용자에게 콘텐츠를 제공하는 방법(출처: AWS Docs) CloudFront 함수는 글로벌 CloudFront 이벤트에 대한 응답으로 함수를 실행할 때마다 호출 횟수를 계산합니다. 자세한 요금 사항은 🌏Amazon CloudFront CDN - 요금제 및 요금에서 확인하실 수 있습니다.   끝맺음 오늘은 스트리밍 서비스에 대해 정리를 해보았습니다. 저는 미디어에 대한 지식이 많이 부족하기 때문에, 생각보다 정리할 것이 많았고(깊게 들어가면 훨씬 많은 내용이 있습니다. . ) 적지 않은 시간을 쓴 것 같습니다. 🥲 다행히 Live Streaming과 VOD streaming 두 가지다 AWS Media Services를 사용한 워크플로(AWS에서 제시해 준)로 구축할 수 있기 때문에 조금 더 쉽게 공부를 한 것 같습니다. AWS Media Services의 서비스들이 아직 서울 리전이 나온 지 얼마 안 되어서 그런지 AWS를 이용한 미디어 서비스 구축 후기에 관한 한국 자료는 많이 찾아볼 수 없었습니다. 그래도 AWS에서 서비스에 대한 정보를 잘 제공해 주기 때문에, 스트리밍 서비스 구축에 고민하고 계신 분들은 AWS Media Services를 잘 활용한다면 안전하고 빠르게 스트리밍 서비스를 구축해볼 수 있을 것 같습니다. 부족한 내용이지만 읽어주셔서 감사합니다. 😀 잘못된 내용은 댓글로 남겨주시면 감사하겠습니다! [참고자료]  AWS 미디어서비스를 통한 라이브 및 온디맨드 동영상 워크플로 구성 및 배포하기 - 김영진:: AWS Builders Online Series AWS Docs AWS 이두잉의 AWS 세상 - AWS Step Functions 이해 AWS CloudFront - 개념"
    }, {
    "id": 12,
    "url": "http://localhost:4000/alb/",
    "title": "ALB(Application Load Balancer)에서 URL 기반 라우팅",
    "body": "2022/08/31 -  💡 Intro: 하나의 도메인에 두 개의 서비스를 할 수 있는지에 대해 묻는 분이 있었습니다. AWS에서 어떻게 구성해야 하는지 🌎AWS Docs를 찾아보다가 ALB(Application Load Balancer)로 가능하다는 것을알게 되었습니다. 이를 URL 기반 라우팅이라고 하는데, 이에 대해서 실습해 보려 합니다.  ⚠️ Classic Load Balancer, Network Load Balancer 및 Gateway Load Balancer 등 다른 로드 밸런서 유형에는 이 기능을 사용할 수 없습니다. ELB는 AWS를 사용하는 분에게는 기본적으로 숙지해야하는 내용이라고 들었기 때문에 초보 개발자인 저도 열심히 공부하고 있습니다. 😭 🔎 ALB(Application Load Balancer)란?: ELB(Elastic Load Balancing) 설명서에는 ALB(Application Load Balancer)에 대해 이렇게 설명 하고 있습니다. Application Load Balancer는 개방형 시스템 간 상호 연결(OSI) 모델의 일곱 번째 계층인 애플리케이션 계층에서 작동합니다. 로드 밸런서는 요청을 받으면 우선 순위에 따라 리스너 규칙을 평가하여 적용할 규칙을 결정한 다음, 규칙 작업의 대상 그룹에서 대상을 선택합니다. 애플리케이션 트래픽의 콘텐츠를 기반으로 다른 대상 그룹에 요청을 라우팅하도록 리스너 규칙을 구성할 수 있습니다. 대상이 여러 개의 대상 그룹에 등록이 된 경우에도 각 대상 그룹에 대해 독립적으로 라우팅이 수행됩니다. 대상 그룹 레벨에서 사용되는 라우팅 알고리즘을 구성할 수 있습니다. 기본 라우팅 알고리즘은 라운드 로빈입니다. 그 대신 최소 미해결 요청 라우팅 알고리즘을 지정할 수 있습니다. - 출처: AWS Docs  Application layer는 OSI 7 Layer의 제일 꼭대기에 있는 계층입니다. 애플리케이션과 데이터를 주고 받기 위한 역할을 하는데, 서버가 이해할 수 있는 메시지(데이터)로 변환하고, 전송 계층에 전달하는 역할을 수행합니다. 애플리케이션 계층에는 웹 사이트를 이용할 때의 HTTP 프로토콜, 파일을 전송할 때 쓰는 FTP 프로포콜, 메일을 보낼 때 쓰는 SMTP 프로토콜 등 다양한 프로토콜이 존재합니다.  아래 이미지와 같이 Load Balancer 아래에는 Listener, Rule, Target Group이 있습니다.  Listener : 구성한 프로토콜 및 포트를 사용하여 클라이언트의 연결 요청을 확인하여 요청을 처리할 적절한 Target Group으로 전달합니다.  Rule : 어떤 대상그룹에 전달해야 할지를 판단하는 기준이 됩니다.  Target Group : 클라이언트의 요청을 처리할 EC2 인스턴스의 집합이며, 지정한 프로토콜과 포트 번호를 사용하여 요청을 라우팅합니다. 이미지 1. ALB 구성 요소(출처: AWS Docs) ALB는 하나 이상의 Listener를 추가할 수 있으며, Listener에는 다수의 Rule을 가질 수 있고, Listener 또한 다수의 Target Group을 가질 수 있습니다.  📚 ALB에서 URL 기반 라우팅을 수행해 보기: AWS Docs를 따라서 진행해 보겠습니다. 서비스 A와 서비스 B라는 두 가지 서비스가 있고 애플리케이션이 포트 80의 이러한 서비스에서 실행되고 있다고 가정합니다. 예를 들어 서비스 A는 /svcA 경로에서 애플리케이션을 실행하고, 서비스 B는 /svcB 경로에서 애플리케이션을 실행합니다. - 출처: AWS Docs 📕 ELB(Application Load Balancer) 생성: [EC2 대시보드]에서 [로드 벨런서]를 들어간 뒤 [로드 밸런서 생성]을 들어갑니다.  이미지 2. 로드 밸런서 생성 [Select load balancer type]에서 [Application Load Balancer]를 Create합니다.  이미지 3. Application Load Balancer 생성 - 1 Load balancer name, VPC, 가용영역을 설정한 후 Summary를 확인하고 생성합니다.  이미지 4. Application Load Balancer 생성 - 2  Internet-facing(인터넷경계) 란, 이름에서 느껴지는 것처럼 인터넷에 연결되는 밸런서를 뜻합니다. 인터넷으로부터 요청을 받아서 각기 다른 EC2로 분배해 주는 역할을 합니다. Internal(내부) 는, private subnet에 연결되어 있는 여러 서버에 연결될 때 사용합니다.  이미지 5. Application Load Balancer 생성 - 3 로드 밸런서 [my-alb]가 생성된 것을 볼 수 있습니다.  이미지 6. Application Load Balancer 생성 - 4 📘 Listeners 규칙 구성: 리스너 규칙 1: 요청 URL 경로에 /svcA 문자열이 포함되어 있으면 요청을 my-tg1로 전달합니다. my-tg1에는 지정된 경로에서 애플리케이션을 실행하는 서비스 A가 포함되어 있기 때문입니다. 리스너 규칙 2: 요청 URL 경로에 /svcB 문자열이 포함되어 있으면 해당 요청을 my-tg2로 전달합니다. my-tg2에는 지정된 경로에서 애플리케이션을 실행하는 서비스 B가 포함되어 있기 때문입니다. - 출처: AWS Docs [로드 밸런서]를 선택한 다음 [리스너(Listeners)]를 선택합니다. 그리고 리스너를 업데이트하기 위해 [규칙 보기/편집(View/edit rules)]을 선택합니다.  이미지 7. 리스너 규칙 보기/편집 상단의 메뉴에서 규칙 추가(Add rules) 아이콘인 [더하기 기호(+)]를 선택합니다.  이미지 8. 리스너 규칙 추가 - 1  우선 순위에 따라 규칙을 삽입할 수 있는 [규칙 삽입(Insert Rule) 아이콘]을 클릭합니다.  /svcA와 /svcB에 경로 기반 규칙 추가를 위해 IF(모두 일치) 부분에서 [조건 추가(Add condition)]를 클릭 후, [경로(Path)]를 선택한 다음 경로 패턴 /svcA를 입력합니다.  THEN 부분에서 [작업 추가(Add action)]를 클릭한 후, [전달(Forward to)]을 선택한 다음 대상 그룹 my-tg1를 선택합니다.  /svcB 또한 똑같이 설정해 줍니다. 이미지 9. 리스너 규칙 추가 - 2 Application Load Balancer의 DNS 이름을 복사하여 URL 경로 끝에 /svcA or /svcA 를 붙여 넣었을 때, 올바른 서비스를 반환하면 테스트가 성공적으로 이루어집니다.  [참고자료]  Application Load Balancer에서 경로 기반 라우팅을 수행하려면 어떻게 해야 하나요? AWS docs - Application Load Balancer Listener rules for your Application Load Balancer https://aws-hyoh. tistory. com/133"
    }, {
    "id": 13,
    "url": "http://localhost:4000/lambda-nat/",
    "title": "VPC내의 AWS Lambda의 인터넷 접속하기",
    "body": "2022/08/19 -  💡 Intro: Amazon Virtual Private Cloud(Amazon VPC)에 연결된 AWS Lambda에 인터넷 접속을 가능하게 하려면, NAT GW(Network Address Translation Gateway) 설정을 해야합니다. 오늘은 이에 대해서 정리해 보려고 합니다.  🔎 AWS Lambda의 세 가지 상태: 저는 Amazon Virtual Private Cloud(Amazon VPC)에 연결된 AWS Lambda에 인터넷 접속을 가능하게 하기 위해, 3번째 케이스인 VPC와 NAT이 있는 상태로 진행해보도록 하겠습니다.  VPC가 없는 상태 : 웹에 자유롭게 접속할 수 있지만, 로컬 네트워크로 AWS 서비스들과 연결할 수 없습니다.  VPC가 있는 상태 : 기본적인 설정으로 로컬 네트워크에 연결이 가능하지만, 웹에는 접속할 수 없습니다.  VPC와 NAT이 있는 상태 : AWS 서비스와 웹 둘 다 접속이 가능합니다. 🔎 Amazon VPC(Amazon Virtual Private Cloud), Subnet, Router, Routing Table, IGW(Internet Gateway), NAT GW(Network Address Translation Gateway)란?: 본 내용에 들어가기전, Amazon VPC, Subnet, Routing Table, IGW, NAT GW에 대해서 먼저 정리하고 넘어가 보도록 하겠습니다. 🌎 Amazon VPC(Amazon Virtual Private Cloud): Amazon VPC란, AWS 클라우드에서 다른 고객과 완벽하게 논리적으로 격리된 네트워크 공간을 제공하여 프로비저닝하여 가상 네트워크에서 AWS 리소스를 만드는데 사용하는 리소스입니다. 쉽게 풀어서 설명하자면, 자신이 사용할 AWS Resource들을 격리 되어진 하나의 네트워크로 묶는 서비스를 의미하며 격리되어 있기 때문에 다른 사람들은 접근하고 보는 것이 불가능해집니다.  만약, VPC 없이 인스턴스를 생성한다면 아래와 같이 인스턴스끼리의 구분없는 연결로 인해 시스템 복잡도가 증가할 것이며, 인터넷을 통해 전달되는 트래픽의 전송이 굉장히 비효율적이게 될 것 입니다. VPC를 적용하면 인스턴스가 VPC에 속함으로써 네트워크를 구분할 수 있고, VPC 별로 필요한 설정을 통해 인스턴스에 네트워크 설정을 적용할 수 있습니다. 또한, 각각의 VPC는 독립적이기 때문에 서로 통신할 수 없습니다. 만일 통신을 원한다면 VPC 피어링 서비스를 통해 VPC 간에 트래픽을 라우팅할 수 있도록 설정할 수 있습니다. ➕ AWS는 VPC의 중요성을 강조하여 2019년부터 거의 모든 서비스에 VPC를 적용하도록 강제하였습니다.  이미지 1. Amazon VPC 🌎 서브넷(Subnet): 서브넷(Subnet) 이란, IP 주소를 나누어 리소스가 배치되는 물리적인 주소 범위입니다. 즉, 서브넷은 VPC를 잘 개 쪼갠 것이며 서브넷을 나누는 이유는 더 많은 네트워크 망을 만들기 위함입니다. 또한 인터넷에 연결되어야 하는 리소스에는 퍼블릭 서브넷(Public Subnet)을 사용하고, 인터넷에 연결되지 않는 리소스에는 프라이빗 서브넷(Private Subnet)을 사용합니다.  이처럼 인터넷 연결 여부로 퍼블릭 서브넷(Public Subnet)과 프라이빗 서브넷(Private Subnet)로 구분하는 이유는 보안을 강화하기 위함입니다. 퍼블릭 서브넷에 존재하는 인스턴스는 인터넷에 연결되어 아웃바운드, 인바운드 트래픽을 주고받을 수 있습니다. 반면 프라이빗 서브넷은 외부에 노출이 되어 있지 않기 때문에 접근할 수 없습니다. 즉, 인터넷과 연결되어 외부에 노출되어 있는 면적을 최소화함으로써 네트워크 망에 함부로 접근하는 것을 막기 위함입니다.  이미지 2. Subnet 🌎 라우팅 테이블(Routing Table)과 라우터(Router): AWS VPC 설명서에는 라우팅 테이블의 역할이 이렇게 소개되어져 있습니다. VPC에는 암시적 라우터가 있으며 라우팅 테이블을 사용하여 네트워크 트래픽이 전달되는 위치를 제어합니다. VPC의 각 서브넷을 라우팅 테이블에 연결해야 합니다. 테이블에서는 서브넷에 대한 라우팅을 제어합니다(서브넷 라우팅 테이블). 서브넷을 특정 라우팅 테이블과 명시적으로 연결할 수 있습니다. 그렇지 않으면 서브넷이 기본 라우팅 테이블과 암시적으로 연결됩니다. 서브넷은 한 번에 하나의 라우팅 테이블에만 연결할 수 있지만 여러 서브넷을 동일한 서브넷 라우팅 테이블에 연결할 수 있습니다. - 출처: AWS Docs 간단하게 설명하자면 라우터(Router)는 목적지이고, 라우팅 테이블(Routing Tabl)은 이정표라고할 수 있습니다. 172. 31. 0. 0/16가 목적지면 이리로 오고, 10. 0. 0. 0/16가 목적지면 절로 가세요. 라고 알려주는 이정표일 뿐인거죠. 만약 목적지가 라우팅 테이블에 명시되지 않은 트래픽들을 라우팅 시키고 싶을 땐 0. 0. 0. 0/0라는 주소를 통해 전달시킬 수 있습니다.  이미지 3. Router 🌎 IGW(Internet Gateway, 인터넷 게이트웨이) / NAT GW(Network Address Translation Gateway, NAT 게이트웨이): 사실상 IGW와 NAT GW 이 두 개를 통해 인터넷 간 통신을 활성화시킬 수 있습니다. IGW는 VPC 리소스와 인터넷 간 통신을 활성화하기 위해 VPC에 연결하며, 퍼블릭 서브넷만 외부와 통신해야 하므로 퍼블릭 서브넷의 라우팅 테이블에만 IGW로 향하는 규칙을 포함합니다. NAT GW는 퍼블릭 서브넷에 위치하여 프라이빗 서브넷에서 발생하는 네트워크 요청을 받은 후, IGW에 패킷을 전달하여 인터넷과 통신할 수 있도록 도와줍니다.  라우팅 테이블을 보면 0. 0. 0. 0/0으로 되어 있는 것을 볼 수 있는데, 목적지의 IP 주소가 172. 31. 0. 0/16(VPC 내부)에 해당하는지 확인하고 해당하지 않는 모든 트래픽에 대하여 IGW로 보내라는 뜻입니다. 즉, 목적지가 라우팅 테이블에 명시되지 않은 모든 트래픽을 라우팅 시키고 싶을 땐 0. 0. 0. 0/0라는 주소를 사용할 수 있습니다.  이미지 4. IGW / NAT GW 📚 VPC내의 AWS Lambda의 인터넷 접속하기: 이제 본격적으로 작업을 실시할 수 있습니다. 🌎Amazon Virtual Private Cloud(Amazon VPC)에 연결된 AWS Lambda 함수에 인터넷 액세스를 제공하려 합니다. 어떻게 설정해야 하나요? 문서에 자세하게 나와있습니다. 그냥 이 순서 그대로 따라하시면 진행하는데 전혀 큰 어려움은 없습니다. 📕 Amazon VPC 설정: AWS Console &gt; VPC로 들어가면, VPC, Subnet, Routing Table, IGW, NAT GW등 앞서 정리한 모든 항목이 있습니다.  이미지 5. AWS Console -&gt; VPC 1. Amazon VPC를 생성합니다.  AWS Console &gt; VPC &gt; VPC 생성 이름 및 IPv4를 지정 / 생성해줍니다. 이미지 6. VPC 생성 버튼 클릭 이미지 7. VPC 생성 2. Amazon VPC에 하나의 퍼블릭 서브넷과 둘 이상의 프라이빗 서브넷을 생성합니다.  AWS Console &gt; VPC &gt; Subnet 생성 이름 및 IPv4과 가용영역을 설정하고, 이전에 만든 VPC를 연결합니다.  Amazon VPC에 하나의 퍼블릭 서브넷과 둘 이상의 프라이빗 서브넷을 생성합니다. (서브넷을 생성할 때, [이름 태그]에 퍼블릭 또는 프라이빗 서브넷을 식별하는 각 서브넷의 이름을 입력합니다. 예: public-Subnet1, private-Lambda-Subnet1, private-Lambda-Subnet2) 이미지 8. 서브넷 생성 버튼 클릭 이미지 9. 서브넷 생성 3. 인터넷 게이트웨이를 생성하여 Amazon VPC에 연결합니다.  AWS Console &gt; VPC &gt; IGW(Internet Gateway) 이름을 생성해준 후, 생성한 IGW를 클릭하여 이전 단계에서 만든 VPC에 연결해줍니다. 이미지 10. 인터넷 게이트웨이 생성 버튼 클릭 이미지 11. 인터넷 게이트웨이 생성 이미지 12. 만들어둔 VPC연결 4. NAT 게이트웨이를 생성합니다.  AWS Console &gt; VPC &gt; NAT GW(Network Address Translation Gateway) 이름을 설정하고 이전에 Public Subnet으로 사용하기 위해 만들었던 Subnet에 연결하여 NAT GW를 생성합니다.  ✅ NAT Gateway는 시간당 0. 059 USD가 부과됩니다. (리전: 아시아 태평양(서울)) 이미지 13. NAT 게이트웨이 생성 버튼 클릭 이미지 14. 만들어둔 서브넷 연결 후 NAT 게이트웨이 생성 5. 퍼블릭 서브넷과 프라이빗 서브넷용 사용자 지정 라우팅 테이블 두 개를 생성합니다.  AWS Console &gt; VPC &gt; Routing Table 이름을 지정하고 이전에 만든 VPC에 연결합니다.  퍼블릭 서브넷과 프라이빗 서브넷용 사용자 지정 라우팅 테이블 두 개를 생성합니다. 이미지 15. 라우팅 테이블 생성 버튼 클릭 이미지 16. 라우팅 테이블 두 개 생성 🧩 퍼블릭 서브넷의 라우팅 테이블의 경우  [Destination]에 [0. 0. 0. 0/0]을 입력합니다.  [Target]에서 IGW를 선택한 다음, 이전에 생성한 IGW의 ID(my-igw1)를 선택합니다.  서브넷 연결 &gt; 서브넷 연결 편집 &gt; Public Subnet 선택 &gt; 저장합니다. 이미지 17. 라우팅 테이블 편집에서 인터넷 게이트웨이 연결 🧩 프라이빗 서브넷의 라우팅 테이블의 경우  [Destination]에 [0. 0. 0. 0/0]을 입력합니다.  [Target]에서 NAT GW 선택합니다. 그런 다음 생성한 NAT GW(my-nat-gw1)의 ID를 선택합니다.  서브넷 연결 &gt; 서브넷 연결 편집 &gt; Private Subnet들 선택 &gt; 저장합니다. 이미지 18. 라우팅 테이블 편집에서 NAT 게이트웨이 연결 📘 Lambda 함수 구성:  Lambda 콘솔에서 함수페이지를 연 후, 본인이 생성한 Amazon VPC에 연결할 함수를 선택합니다.  [구성] &gt; VPC &gt; [편집]을 선택합니다. 이미지 19. Lambda 함수 VPC 편집 선택  VPC를 선택한 후, 만들어 둔 Private Subnet을 선택합니다.  [보안 그룹]에서 보안 그룹을 선택합니다. (참고 : 기본 보안 그룹을 사용해도 모든 아웃바운드 인터넷 트래픽을 허용하며, 대부분의 경우에 충분합니다. 자세한 내용은 VPC의 보안 그룹을 참조하십시오. - 출처: AWS Docs) 이미지 20. VPC 편집  끝맺음 VPC, NAT GW, IGW 등에 대해 다시 정리를 해보려다 직접 연결을 해보면서 하는 것이 나을 것 같아서, 예시로 Lambda에 연결하는 부분까지 다시 정리해 보았습니다. 내용을 정리하면서 여러 정보를 찾았는데, 결론은 다들 요금 주의,,,,,,😭 NAT GW에서 쓸데없는 요금이 나가는 경우도 있더라고요. 다음에는 AWS를 하면서 주의해야 할 요금에 대해 정리를 해보려 합니다. (솔직히 아직 AWS에 대해 초보이다 보니, 이번에 강전희 님과 정태환 님이 번역하신 AWS 비용 최적화 바이블 - 핀옵스를 위한 최적의 기술 활용부터 운영 노하우까지를 샀습니다…. 빨리 다 읽어보고 한번 정리를 해보려고 합니다!😃) [참고자료]  AWS docs - VPC, Subnet https://aws. amazon. com/ko/premiumsupport/knowledge-center/internet-access-lambda-function/ https://medium. com/@kimjnsjwj/vpc내의-aws-lambda의-인터넷-접속-bc503e9940f5 https://jbhs7014. tistory. com/164 https://err-bzz. oopy. io/c4abbed2-fc30-4061-81b0-2803c4a59809 AWS docs - VPC의 보안 그룹"
    }, {
    "id": 14,
    "url": "http://localhost:4000/interview3/",
    "title": "신입 백앤드 개발자(나)를 위한 면접 질문 정리 - 기타(공통, 인프라/클라우드(AWS), 컨테이너)",
    "body": "2022/08/13 -  💡 Intro: 신입 백앤드 개발자를 위한 면접 질문 정리 - 기타(공통, 인프라/클라우드(AWS), 컨테이너) 에서는 프로그래밍 공통 질문과 트러블 슈팅, 인프라/클라우드, 컨테이너 등에 대한 면접 질문을 다루어 보려고 합니다.  🔎 개발 면접 질문 - 공통: 1. DevOps란 무엇인가요?: 데브옵스(Dev(개발) Ops(운영))란, 애플리케이션 개발-운영 간의 협업 프로세스를 자동화하는 것을 말하는 개발 방법론 이며, 결과적으로 애플리케이션의 개발과 개선 속도를 빠르게 합니다.  과거 새로운 서비스를 출시하기 위해서 오랜기간 작업 후 배포했던 것과 달리, 현재는 서비스 출시 속도가 다르고 업데이트 주기 또한 빈번해 졌습니다. 때문에 개발된 소프트웨어가 시스템의 안정성을 유지하면서 사용자에게 빠르게 제공될 수 있도록 업무 사이클을 자동화 시킬 수 있도록 하는 데브옵스와 같은 개발 방법론이 등장 했습니다.  2. CI/CD란 무엇인가요? 적용해 본 적이있다면 설명해 주세요. : CI(Continuous Integration)/CD(Continuous Deployment)란, 서비스 빌드부터 배포까지 애플리케이션 개발 단계를 자동화 하는 과정입니다. 예를 들어 Github으로 코드를 커밋하고 Jenkins가 자동으로 빌드하도록 설계해본 경험 등에 대해 설명하면 될 것 같습니다.  CI/CD에 대한 경험이 부족하거나 깊이 있게 공부하고 싶으면 🌎CI/CD가 뭔가요? 이론편과, 🌎CI/CD가 뭔가요? 실전편에서 자세하게 다루어 볼 수 있습니다.  3. Test Code에 대해서 알고 계신가요? 그렇다면 왜 작성해야 할까요?: 테스트 코드란 내가 작성한 메서드가 실제로 제대로 동작하는지에 대해 테스트를 하는 코드입니다. 테스트 코드는 잘 작동하고, 깔끔한 코드를 얻기 위해서 작성합니다.  필자의 예시 : 저는 테스트 코드에 대해 잘 알지 못할 때 코드를 배포하기 전, 코드 수정 -&gt; 서버동작 -&gt; 테스트에 필요한 데이터를 DB에 입력 -&gt; 테스트 -&gt; DB 데이터 정리 -&gt; 과정 반복등의 단계를 겪었습니다. 그 후 테스트 코드를 알고 나서 코드 수정 -&gt; 테스트 코드 실행 -&gt; 결과 확인 정도로 많은 시간을 절약할 수 있었습니다. 이러한 테스트 코드의 장점은 시간절약, 문서로서의 역할 가능(보통 값이 주어짐(given), 무엇을 했을 때(when) 어떤 값을 원함(then)의 구조이기 때문에 가독성이 뛰어남), 깔끔한 인터페이스등이 있습니다.  4. TDD(Test-Driven Development)에 대해 설명해 주세요. : TDD란 작은 단위의 테스트 케이스를 작성하고 그에 맞는 코드를 작성하여 테스트를 통과한 후에 상황에 맞게 리팩토링하는 테스트 주도 개발 방식을 말합니다. 레드 그린 사이클이라는 3가지 과정을 거치는데,  Red - 항상 실패하는 테스트를 먼저 작성하고, Green - 테스트가 통과하는 프로덕션 코드를 작성한 후, Refactor - 작성한 프로덕션 코드를 깨끗하고 가독성 좋게 리펙토링합니다. 5. DDD(Domain-Driven Design)에 대해 설명해 주세요. : DDD란, 각 비즈니스 도메인이 중심이 되어 진행하는 개발 방식으로 소프트웨어의 연관된 부분들을 연결하여 계속해서 진화하는 새로운 모델을 만들어나가 복잡한 애플리케이션을 만드는 것을 쉽게 해주는 것에 있습니다. 도메인 전문가와 IT 개발자 간의 커뮤니케이션과 협업을 통해서 모델을 발전시키는 것을 추구합니다. 쇼핑몰을 예로 들면 손님들이 주문하는 도메인, 점주들이 관리하는 도메인 등이 있을 수 있습니다. 이러한 도메인들이 서로 상호작용하며 설계하는 것이 도메인 주도 설계입니다.  이미지 1. DDD(Domain-Driven Design) 6. Monolithic Architecture와 MSA(Microservice Architecture)의 차이점에 대해 설명해 주세요. : 모놀리식 아키텍쳐는 모든 시스템의 구성요소가 한 프로젝트에 통합되어 있는 하나의 통합된 패키지로 개발하는 방식입니다. 반면에, 마이크로 서비스는 1개의 시스템을 독립적으로 배포가능한 각각의 서비스로 분할하는 개별 서비스 단위로 개발하는 방식입니다. 때문에 마이크로 서비스는 개별 서비스 단위로 나뉘어져 있어서 해당 부분만 수정 또는 배포하기 좋고, 필요한 부분만 확장하기에도 용이하다는 장점이 있습니다.  이미지 2. MSA(Microservice Architecture) 7. 트러블슈팅(troubleshooting)을 경험해 보셨나요?: 개발을 하면서 발생한 문제를 어떻게 해결했는지, 원인 규명 -&gt; 사실 정리 -&gt; 원인 추론 -&gt; 조치 및 방안 검토 -&gt; 해결 과정을 차근차근 설명하시면 될 것같습니다. 추가로 알게 된 개념 혹은 방법을 곁들여서 함께 설명할 수 있으면 더 좋을 것 같습니다.  🔎 개발 면접 질문 - 컨테이너: 1. Docker에 대해 설명해 주세요. : 도커는 컨테이너 기술을 기반으로한 가상화 플랫폼입니다. 기존의 가상화는 하드웨어를 가상화하여 무거운데다, 반드시 하이퍼바이저를 거쳐야 하기 때문에 속도 저하가 발생했습니다. 이러한 이유로 베이스 환경의 OS를 공유하면서 필요한 프로세스만 격리시킨 컨테이너를 통해 가상화를 하는 Docker같은 기술이 등장했습니다.  이미지 3. VM과 Docker의 차이  가상 머신을 생성하기 위해서는 하이퍼바이저 또는 가상 머신 모니터라고 불리는 소프트웨어를 이용합니다. 하이퍼바이저는 호스트 하드웨어에 설치되어 호스트와 게스트를 나누는 역할을 하고, 각각의 게스트는 하이퍼바이저에 의해 관리되며 시스템 자원을 할당받게 됩니다. 하이퍼바이저와 달리 컨테이너는 가상의 OS를 만드는 것이 아닙니다. 컨테이너는 베이스 환경의 OS를 공유하면서 필요한 프로세스만 격리하는 방식으로, 커널을 공유하기 때문에 호스트 OS의 기능을 모두 사용할 수 있습니다. 그렇기 때문에 컨테이너 위에서는 호스트 OS와 다른 OS를 구동할 수 없습니다. 대신 격리시킬 애플리케이션과 거기에 필요한 파일이나 특정 라이브러리 등 종속 항목만 포함하기 때문에 배포를 위해 생성되는 이미지의 용량이 작아진다는 장점이 있습니다. 운영체제가 아닌 프로세스이며, 하이퍼바이저를 거칠 필요가 없어 실행 속도가 빠르기도 합니다.  2. Dockerfile, Docker-Compose, Docker Image와 Container의 차이, Docker Hub:  Dockerfile : Dockerfile은 이미지를 생성하기 위한 용도로 컨테이너에 설치해야하는 패키지, 소스코드, 명령어, 환경변수설정 등을 기록한 하나의 파일 Docker-Compose : 여러 컨테이너들을 한 번에 관리를 할 수있게 도와주는 파일 Docker Image와 Container의 차이 : 서비스 운영에 필요한 서버 프로그램, 소스코드 및 라이브러리, 컴파일된 실행 파일을 묶은 것을 Docker image라 하며, Image를 실행한 상태를 Container라고 함 Docker Hub : Docker에서 운영하는 Docker 이미지 저장소 서비스3. k8s(Kubernetes)에 대해서 설명해 주세요. : 쿠버네티스(Kubernetes)란, 컨테이너화된 애플리케이션의 배포, 확장 및 관리를 자동화하는 오픈 소스 시스템입니다.  3-1. 쿠버네티스 클러스터의 기본 아키텍처에 대해 설명해 주세요. : 3-2. 쿠버네티스에서 Auto Scaling의 원리에 대해 설명해 주세요. :  아직 k8s에 대해 익숙하지 않아서 열심히 공부하는 중입니다;ㅅ;. 🌎kubernetes 공식 문서에서 깊이 있게 공부하실 수 있습니다.  🔎 개발 면접 질문 - 인프라/클라우드: 1. AWS 인프라를 구축해본 경험에 대해 설명해 주세요. : AWS를 사용해본 경험에 대하여 설명해 주시면 될 것 같습니다.  2. 서버리스(Serverless)란 무엇인가요?: 서버리스 컴퓨팅(Serverless Computing)이란 IT 인프라를 데이터센터 또는 클라우드에 준비 없이 필요한 기능을 함수로 구현해서 관리하는 것을 의미 합니다. 추가로 서버리스 컴퓨팅을 사용해본 경험에 대해 질문이 들어온다면, AWS Lambda와 같은 서버리스 컴퓨팅 플랫폼을 사용해본 경험에 대해 설명하시면 될 것 같습니다.  서버리스 컴퓨팅은 IT 인프라를 데이터센터 또는 클라우드에 준비 없이, 필요한 기능을 함수(Function) 형태로 구현하고, 자동 스케일링 방식으로 시시각각 변하는 자원 수요를 지원하며 전통적인 백엔드를 대신합니다. 따라서 서버리스 컴퓨팅을 FaaS(Function as a Service) 라고도 하고 백엔드 시스템을 보이지 않는 서비스로 추상화하였기 때문에 BaaS(Backend as a Service) 라고도 합니다.  이미지 4. 기술의 발전 3. Amazon VPC(Amazon Virtual Private Cloud)란 무엇인가요?: AWS 클라우드에서 다른 고객과 완벽하게 논리적으로 격리된 네트워크 공간을 제공하여 프로비저닝하여 가상 네트워크에서 AWS 리소스를 만드는데 사용하는 리소스입니다. 쉽게 풀어서 설명하자면, 자신이 사용할 AWS Resource들을 격리 되어진 하나의 네트워크로 묶는 서비스를 의미하며 격리되어 있기 때문에 다른 사람들은 접근하고 보는 것이 불가능해집니다.  만약, VPC 없이 인스턴스를 생성한다면 인스턴스끼리의 구분없는 연결로 인해 시스템 복잡도가 증가할 것이며, 인터넷을 통해 전달되는 트래픽의 전송이 굉장히 비효율적이게 될 것 입니다. VPC를 적용하면 인스턴스가 VPC에 속함으로써 네트워크를 구분할 수 있고, VPC 별로 필요한 설정을 통해 인스턴스에 네트워크 설정을 적용할 수 있습니다. AWS는 VPC의 중요성을 강조하여 2019년부터 거의 모든 서비스에 VPC를 적용하도록 강제하였습니다.  3-1. Amazon VPC에 따른 AWS Lambda의 상태에 대해 설명해주세요. :  VPC가 없는 상태 : 웹에 자유롭게 접속할 수 있지만, 로컬 네트워크로 AWS 서비스들과 연결할 수 없습니다.  VPC가 있는 상태 : 기본적인 설정으로 로컬 네트워크에 연결이 가능하지만, 웹에는 접속할 수 없습니다.  VPC와 NAT이 있는 상태 : AWS 서비스와 웹 둘 다 접속이 가능합니다. 3-2. NAT(Network Address Translation, 네트워크 주소 변환) Gateway란 무엇인가요?: NAT(Network Address Translation, 네트워크 주소 변환) Gateway란, 외부 서비스에서 프라이빗 서브넷의 인스턴스로 접근할 수 없게 하되, 프라이빗 서브넷의 인스턴스에서는 외부 서비스로 접근할 수 있게 해주는 서비스 입니다.  이미지 5. NAT GW (Network Address Translation Gateway) 4. 만약 클라이언트의 수가 늘어나게 되면서 기존 서버만으로는 정상적인 서비스가 불가능하게 되었습니다. 이럴 때는 어떠한 방법이 있을까요?: 증가한 트래픽에 대처할 수 있는 방법은 크게 서버 자체의 성능을 확장하는 Scale-up 방식과 서버를 여러대로 나눠서 트래픽을 처리하는 Scale-out의 방법이 있습니다. 또한, Scale-out의 방식은 여러 대의 서버로 트래픽을 균등하게 분산해주는 로드밸런싱이 반드시 필요합니다.  4-1. 로드 밸런서(Load Balancer)에 대해서 설명해 주세요. : 로드 밸런서란, 서버에 가해지는 트래픽을 여러 대의 서버에게 균등하게 분산시켜주는 역할을 합니다. 또한, 여러 대의 서버 덕분에 무중단 서비스 제공할 수 있습니다.  로드 밸런싱의 종류와 알고리즘, 장애 대비 및 ELB(Elastic Load Balancer), ALB(Application Load Balancer), NLB(Network Load Balancer)에 대해서 미리 공부하고 가시는 것을 추천드립니다. 🌎[AWS] 로드 밸런서란?, Load Balancer 장애 대비 5. 무중단 시스템으로 가기 위해 필요한 방법에 대한 본인의 생각을 말해주세요. : 다운 타임이 발생하지 않도록 기본적으로 두 대 이상의 서버를 서비스해야 합니다. 비용 절감을 위해 배포할 때에만 새롭게 서비스를 띄우고, 배포가 완료된 후에는 기존 서버는 셧다운 시키면 될 것 같습니다.  6. Forward Proxy와 Reverse Proxy에 대해 설명해 주세요. : Forward Proxy : 클라이언트에서 서버로 리소스를 요청할 때 직접 요청하지 않고 프록시 서버를 거쳐서 요청합니다. 특정 컨텐츠에 접근하는 것을 방지할 수 있으며, 유저의 정체를 숨겨줄 수도 있습니다.  이미지 6. Forward Proxy Reverse Proxy : 애플리케이션 서버의 앞에 위치하여 클라이언트가 서버를 요청할 때 리버스 프록시를 호출하고, 리버스 프록시가 서버로부터 응답을 전달받아 다시 클라이언트에게 전송하는 역할을 합니다. 로드 밸런싱(load balancing)에 사용되고 있으며, SSL 암호화와 보안에 좋다는 장점이 있습니다.  NginX, Apache Web Server 등의 오픈 소스 소프트웨어에서 지원하고 CloudFlare, AWS CloudFront 같은 CDN 서비스도 마찬가지로 리버스 프록시 서버를 사용하고 있습니다.  이미지 7. Reverse Proxy 7. AWS 리전(Region)과 가용 영역(Availability Zone, AZ)에 대해 설명해 주세요. : 8. Snapshot에 대해 설명해 주세요. : 8-1. EC2 AMI(Amazon Machine Image)와 Snapshot의 차이점에 대해 설명해 주세요. : 기본적으로 EBS(Elastic Block Store)를 백업한다는 점에서는 AMI(Amazon Machine Image)와 Snapshot은 동일하지만, AMI는 EC2 인스턴스에 연결되어 있는 모든 EBS Volume을 동시에 백업하는 것이라면 Snapshot 기능은 여러분들이 선택한 EBS Volume을 백업한다는 점에서 차이점이 있습니다. 또한 Snapshot은 AMI 주기적인 백업 기능을 제공해주지만, AMI는 제공하지 않습니다.   끝맺음 공부를 하면서 질문에 괜찮은 내용이 있으면 요약하면서 계속 추가하고 있습니다. 또한, 기본적인 이론에 대해 다시 공부를 하려고 정리한 내용이기 때문에 잘못된 부분들이 있을 수도 있습니다. 잘못된 정보가 보이거나, 부족한 내용, 추가되면 좋을 것 같은 내용이 있다면 댓글에 적어주시면 감사하겠습니다!😊 [참고자료]  CI/CD가 뭔가요? 실전편, CI/CD가 뭔가요? 이론편 Domain Driven Design 이란 무엇인가? https://kubernetes. io/ko/docs/home/ [AWS] 로드 밸런서란? [Infra] 리버스 프록시(reverse proxy) 서버 개념 https://docs. aws. amazon. com/ko_kr/vpc/latest/userguide/what-is-amazon-vpc. html https://aws. amazon. com/ko/premiumsupport/knowledge-center/internet-access-lambda-function/ JIPA님 블로그 WS DevOps와 ECR을 통한 Elastic Beanstalk 배포 환경 구축 및 타 환경과의 비교"
    }, {
    "id": 15,
    "url": "http://localhost:4000/interview2/",
    "title": "신입 백앤드 개발자(나)를 위한 면접 질문 정리 - 데이터베이스",
    "body": "2022/07/28 -  💡 Intro: 신입 백앤드 개발자를 위한 면접 질문 정리 - 데이터베이스에서는 데이터베이스에 대한 전반적인 면접 질문을 다루어 보려고 합니다.  🔎 개발 면접 질문 - 데이터베이스: 1. SQL SELECT 쿼리 문법 순서와 실행 순서에 대해서 설명해 주세요. :  SQL 문법 순서 : SELECT -&gt; FROM -&gt; WHERE -&gt; GROUP BY -&gt; HAVING -&gt; ORDER BY SQL 실제 실행 순서 : FROM(각 테이블 확인) -&gt; ON(조인 조건 확인) -&gt; JOIN(테이블 조인(병합)) -&gt; WHERE(데이터 추출 조건 확인) -&gt; GROUP BY(특정 칼럼으로 데이터 그룹화) -&gt; HAVING(그룹화 이후 데이터 추출 조건 확인) -&gt; SELECT(데이터 추출) -&gt; DISTINCT(중복 제거) -&gt; ORDER BY(데이터 정렬) -&gt; LIMIT 2. 데이터베이스에서 인덱스를 사용하는 이유와 장점, 단점에 대해서 설명해 주세요. : 인덱스란, 테이블을 처음부터 끝까지 검색하는 방법인 FTS(Full Table Scan)과는 달리 인덱스를 검색하여 해당 자료의 테이블을 엑세스하는 방법입니다. 즉, 인덱스를 잘 사용하면 데이터베이스의 테이블에서 필요한 데이터를 빨리 찾을 수 있다는 장점이 있습니다. 인덱스의 단점이라하면 추가, 수정, 삭제 연산시에는 인덱스를 형성하기 위한 추가적인 연산이 수행되기 때문에 실행 속도가 느릴 수 있습니다.  3. RDBMS와 NoSQL에 대해서 설명한 후 그 두 가지의 차이점에 대해서 설명해 주세요. :  RDBMS는 데이터베이스를 이루는 객체들의 릴레이션을 통해서 데이터를 저장하는 데이터베이스입니다.  NOSQL은 RDBMS에 비해 자유로운 형태로 데이터를 저장합니다. 또한 수평확장을 할 수 있고 분산처리를 지원합니다. RDBMS와 NoSQL의 가장 큰 차이점은 RDBMS는 정해진 스키마가 존재하지만, NoSQL은 정해진 스키마가 없다는 것입니다. NoSQL은 정해진 스키마가 없을 때 데이터 구조 변화가 자유롭고 데이터 분산이 용이하다는 장점이 있지만, 데이터 중복 또는 변경시에 연산이 오래걸릴 수 있다는 단점이 있습니다.  4. 트랜잭션에 대해서 설명해 주세요. : 트랜잭션이란 데이터베이스의 상태를 변화시키는 하나의 논리적인 작업 단위라고 할 수 있으며, 작업의 완전성을 보장해 줍니다. 즉, 작업들을 모두 처리하거나 처리하지 못할 경우 이전 상태로 복구하여 작업의 일부만 적용되는 현상이 발생하지 않게 해줍니다.  4-1. 트랜잭션의 ACID에 대해서 설명해 주세요. : ACID는 트랜잭션이 안전하게 수행된다는 것을 보장하기 위한 성질입니다.  Atomicity(원자성) : 트랜잭션의 연산은 모든 연산이 완벽히 수행되어야 하며, 한 연산이라도 실패하면 트랜잭션은 실패해야 합니다.  Consistency(일관성) : 트랜잭션을 수행하기 전이나 후나 데이터베이스는 항상 일관된 상태를 유지해야 합니다.  Isolation(고립성) : 트랜잭션은 동시에 실행될 경우 다른 트랜잭션에 의해 영향을 받지 않고 독립적으로 실행되어야 합니다.  Durability(지속성) : 트랜잭션이 완료된 이후에는 시스템 오류가 발생하더라도 완료된 상태로 영구히 저장되는 것을 보장해야 합니다. 4-2. 트랜잭션 격리 수준(Transaction Isolation Levels)에 대해서 설명해 주세요. :  READ UNCOMMITTED : 다른 트랜잭션에서 커밋되지 않은 내용도 참조할 수 있습니다.  READ COMMITTED : 다른 트랜잭션에서 커밋된 내용만 참조할 수 있습니다.  REPEATABLE READ : 트랜잭션에 진입하기 이전에 커밋된 내용만 참조할 수 있습니다.  SERIALIZABLE : 트랜잭션에 진입하면 락을 걸어 다른 트랜잭션이 접근하지 못하도록 합니다. (성능이 매우 떨어질 수 있음) 5. DB Lock에 대해 설명해주세요. : DB Lock은 트랜잭션 처리의 순차성을 보장하기 위한 방법입니다.  공유락(LS, Shared Lock) : Read Lock라고도 하는 공유락은 트랜잭션이 읽기를 할 때 사용하는 락이며, 데이터를 읽기만 하기 때문에 같은 공유락 끼리는 동시에 접근이 가능합니다.  베타락(LX, Exclusive Lock) : Write Lock라고도 하는 베타락은 데이터를 변경할 때 사용하는 락입니다. 트랜잭션이 완료될 때까지 유지되며, 베타락이 끝나기 전까지 어떠한 접근도 허용하지 않습니다. 6. 정규화에 대해서 설명해 주세요. : 정규화는 데이터의 중복방지, 무결성을 충족시키기 위해 데이터베이스를 설계하는 것을 의미합니다.  제1정규형 : 모든 속성 값이 원자 값을 갖도록 분해합니다.  제2정규형 : 제1정규형을 만족하고, 기본키가 아닌 속성이 기본키에 완전 함수 종속이도록 분해합니다. (여기서 완전 함수 종속이란 기본키의 부분집합이 다른 값을 결정하지 않는 것을 의미합니다. ) 제3정규형 : 제2정규형을 만족하고, 기본키가 아닌 속성이 기본키에 직접 종속(비이행적 종속)하도록 분해합니다. (여기서 이행적 종속이란 A-&gt;B-&gt;C가 성립하는 것으로, 이를 A,B와 B,C로 분해하는 것이 제3정규형입니다. ) BCNF 정규형 : 제3정규형을 만족하고, 함수 종속성 X-&gt;Y가 성립할 때 모든 결정자 X가 후보키가 되도록 분해합니다. 7. 이상 현상에 대해서 설명해 주세요. : 이상 현상은 테이블을 설계할 때 잘못 설계하여 데이터를 삽입,삭제,수정할 때 생기는 논리적 오류를 말합니다. 이상 현상의 종류는 다음과 같습니다.  삽입 이상 : 자료를 삽입할 때 특정 속성에 해당하는 값이 없어 NULL을 입력해야 하는 현상 수정 이상 : 중복된 데이터 중 일부만 수정되어 데이터 모순이 일어나는 현상 삭제 이상 : 어떤 정보를 삭제하면, 의도하지 않은 다른 정보까지 삭제되어버리는 현상 8. Redis에 대해서 간단히 설명해 주세요. : Redis는 key-value store NOSQL DB입니다. 싱글스레드로 동작하며 자료구조를 지원합니다. 그리고 다양한 용도로 사용될 수 있도록 다양한 기능을 지원합니다. 데이터의 스냅샷 혹은 AOF 로그를 통해 복구가 가능해서 어느정도 영속성도 보장됩니다.  8-1. 그렇다면 Redis를 왜 사용하나요?: 사용자가 늘어남에 따라 DB에 부하가 가해지기 시작합니다. 이 부하를 줄이기 위해 한 번 읽어온 데이터를 저장하고, 다시 요청하는 경우 빠르게 결과 값을 받을 수 있도록(캐싱) 하기 위해 Redis를 사용합니다.  이미지 1. Redis 여기서 캐시가 Redis가 되며 look aside cache 기준으로 가장 먼저 캐시에 데이터가 있는지 확인하고, 데이터가 있으면 캐시 데이터 사용합니다. 데이터가 없으면 실제 DB데이터 사용한 후 DB데이터를 캐시에 저장합니다.  9. Elasticsearch에 대해서 설명해 주세요. : Apache Lucene(아파치 루씬) 기반의 java 오픈소스 분산 검색 엔진이며, 역색인(Inverted Index) 구조로 데이터를 저장해서, 전체 텍스트 검색시에 RDBMS에 비해 뛰어난 성능을 보장합니다. 또한, 데이터 저장소가 아니기 때문에 관계형 데이터베이스(RDBMS: mysql, oracle, mariadb)를 대체할 수 없습니다.  🌎역색인(Inverted Index)이란? 주어진 키워드에 대해서 해당 키워드가 포함된 데이터의 위치를 추적해내는 것을 의미합니다. 쉽게 말해서 색인은 데이터베이스 내의 데이터들로부터 키워드를 뽑아내는 과정이라면, 역색인은 특정 키워드에 대해 요청(Request)이 들어왔을때 해당 키워드들을 포함하고 있는 데이터들을 찾아내는 것을 의미합니다. 색인(Index)을 책 맨 앞의 목차라고 한다면, 역색인(Inverted Index)은 책 맨 뒷 부분의 색인이라고 할 수 있습니다.  9-1. Elasticsearch의 인덱스 구조와 RDBMS의 인덱스 구조의 차이에 대해 설명해 주세요. : Elasticsearch는 역색인(Inverted Index) 구조로 데이터를 저장합니다. 반면 RDBMS는 B-Tree와 그와 유사한 인덱스를 사용합니다. 데이터가 어디에 존재하는지, 또는 어떤 순서로 저장하는지의 차이라고 생각합니다.  9-2. Elasticsearch의 키워드 검색과 RDBMS의 LIKE 검색의 차이에 대해 설명해 주세요. : RDBMS는 단순 텍스트매칭에 대한 검색만을 제공해 동의어나 유의어 같은 검색은 불가능합니다. 하지만 Elasticsearch는 동의어나 유의어를 활용한 검색이 가능하며, 비정형 데이터의 색인과 검색이 가능하고, 역색인(Inverted Index) 지원으로 매우 빠른 검색이 가능합니다.  10. CAP 이론과, Eventual Consistency에 대해서 설명해 주세요. : 이미지 2. CAP 이론 CAP 이론은 분산 환경에서 모두를 만족하는 시스템은 없다는 이론입니다. 즉, CAP 세 가지 속성을 모두 만족하는 부분은 존재하지 않으며, 오직 두 가지만 만족할 수 있다로 정리되는 이론입니다.  Consitenty(일관성) : ACID의 일관성과는 약간 다릅니다. 모든 노드가 같은 시간에 같은 데이터를 보여줘야 한다는 것입니다.  Availability(가용성) : 모든 동작에 대한 응답이 리턴되어야 합니다.  Partition Tolerance(분할 내성) : 시스템 일부가 네트워크에서 연결이 끊기더라도 동작해야 합니다. Eventual Consistency이란, Consistency를 보장해주지 못하기 때문에 나온 개념으로, Consistency를 완전히 보장하지는 않지만 결과적으로 언젠가는 Conssistency가 보장됨을 의미합니다.  CAP 이론은 허점이 있는데, 그 허점에 대한 내용과 CAP 이론으로 부족한 부분을 보완하기위해 나온 PACELC 이론은 🌎CAP 이론과 PACELC 이론에서 자세한 내용을 다루어 볼 수 있습니다.  11. ORM(Object Relational Mapping)에 대해서 설명해 주세요. : ORM(Object Relational Mapping)이란, 객체와 관계형 데이터베이스 매핑의 줄임말 입니다. 우리가 OOP(Object Oriented Programming)에서 쓰는 객체라는 개념을 구현한 클래스와RDB(Relational DataBase)에서 쓰이는 데이터인 테이블을 매핑하는 것을 의미합니다. ※ 추가로, SQLAlchemy 혹은 Django ORM등 본인이 사용한 ORM을 예시로 들며 추가 설명을 해주면 좋을 것 같습니다.  12. Replciation과 Clustering에 대해 설명해 주세요. : 🧩 리플리케이션(Replciation)  여러 개의 DB를 권한에 따라 수직적인 구조(Master-Slave)로 구축하는 방식입니다.  비동기 방식으로 노드들 간의 데이터를 동기화합니다.  장점 : 비동기 방식으로 데이터가 동기화되어 지연 시간이 거의 없습니다.  단점 : 노드들 간의 데이터가 동기화되지 않아 일관성있는 데이터를 얻지 못할 수 있습니다. 🧩 클러스터링(Clustering)  여러 개의 DB를 수평적인 구조로 구축하여 Fail Over한 시스템을 구축하는 방식입니다.  동기 방식으로 노드들 간의 데이터를 동기화합니다.  장점 : 1개의 노드가 죽어도 다른 노드가 살아 있어 시스템을 장애없이 운영할 수 있습니다.  단점 : 여러 노드들 간의 데이터를 동기화하는 시간이 필요하므로 리플리케이션에 비해 쓰기 성능이 떨어집니다. 13. 데이터베이스 튜닝(Tuning)과 방법에 대해서 설명해 주세요. : DB 튜닝이란 DB의 구조나, DB 자체, 운영체제 등을 조정하여 DB 시스템의 전체적인 성능을 개선하는 작업을 말합니다. 튜닝은 DB 설계 튜닝 → DBMS 튜닝 → SQL 튜닝 단계로 진행할 수 있습니다.  표 1. DB tuning 14. ELK Stack에 대해서 설명해 주세요. : ELK는 분석 및 저장 기능을 담당하는 ElasticSearch, 수집 기능을 하는 Logstash, 이를 시각화하는 도구인 Kibana의 앞글자만 딴 단어이며, ELK는 접근성과 용이성이 좋아 최근 가장 핫한 Log 및 데이터 분석 도구입니다.  Elasticsearch : ElasticSearch는 Lucene 기반으로 개발한 분산 검색엔진으로, Logstash를 통해 수신된 데이터를 저장소에 저장하는 역할을 담당합니다. (자세한 내용은, 9번 문제로 가주세요. 😊) Logstash : 오픈소스 서버측 데이터 처리 파이프라인으로, 다양한 소스에서 동시에 데이터를 수집하고 변환하여 stash 보관소로 보냅니다.  Kibana : 데이터 시각화 및 탐색 툴로 Elasticsearch 상의 데이터를 쉽게 다룰 수 있게 해줍니다.  주로 묶어서 많이 사용하기 때문에 ELK라고 부르지만, 각각의 도구들 전부 확장성이 뛰어나기 때문에 다른 도구로 대체 혹은 제외가 가능합니다.  추가로, Logstash는 데이터 수집의 역할을 맡고 있으면서, 원하는 형태로의 데이터 입출력 변환 기능까지 맡고 있었기 때문에, 데이터의 수집(파일 추적 등의 여러 단일 목적 데이터 수집 제품들)만을 담당하는 경량화된 모듈 Beats가 도입되었습니다. 그로 인해 기존의 ELK Stack은 Beats가 포함되어 Elastic Stack이 되었습니다. 따라서 Elastic Stack의 Data Flow는 아래 이미지와 같습니다.  이미지 3. Elastic Stack의 Data Flow  끝맺음 공부를 하면서 질문에 괜찮은 내용이 있으면 요약하면서 계속 추가하고 있습니다. 또한, 기본적인 이론에 대해 다시 공부를 하려고 정리한 내용이기 때문에 잘못된 부분들이 있을 수도 있습니다. 잘못된 정보가 보이거나, 부족한 내용, 추가되면 좋을 것 같은 내용이 있다면 댓글에 적어주시면 감사하겠습니다!😊 [참고자료]  https://smjeon. dev/etc/interview-question/ minsgy-백엔드 개발자 [면접/학습내용] redis란? Elasticsearch가 빠르다는데. . ? inverted index?"
    }, {
    "id": 16,
    "url": "http://localhost:4000/interview1/",
    "title": "신입 백앤드 개발자(나)를 위한 면접 질문 정리 - 네트워크, 운영체제",
    "body": "2022/07/22 -  💡 Intro: 백앤드 개발자가 기본적으로 알아야 하는 개념을 다시 한번 정리할 겸 하여 백앤드 개발자를 준비하면서 받았던 면접 질문, 그동안 학습하였던 내용 그리고 예상 가능한 질문을 정리해 보았습니다. 기본적인 백앤드 개념, 서버와 시스템에 대한 이해도의 내용을 중점으로 하였습니다. 당연하게도 정리돼 있는 질문들에 대해 딥 한 질문들이 들어올 수 있으니 깊이 있게 공부하셔야 합니다. 또한 ‘이 정도 질문들에 스스로 대답할 수 있는 정도의 기본기를 내가 가지고 있구나’를 확인하는 방향으로 공부해도 좋을 것 같습니다. 😊 🔎 개발 면접 질문 - 네트워크: 1. HTTP와 HTTPS에 대해 설명해 주세요. : HTTP(Hyper Text Transfer Protocol)이란 데이터를 주고 받기 위한 프로토콜이며, 서버/클라이언트 모델을 따릅니다. 또한 HTTP는 평문 데이터를 전송하는 프로토콜이기 때문에, HTTP로 중요한 정보를 주고 받으면 제 3자에 의해 조회될 수 있습니다. 이러한 문제를 해결하기 위해 HTTP에 암호화가 추가된 프로토콜이 HTTPS입니다.  이미지 1. HTTP와 HTTPS의 차이 공개키(인증서)로 암호화된 메세지는 개인키를 가지고 있어야만 복호화가 가능하기 때문에, 서버(기업)을 제외한 누구도 원본 데이터를 얻을 수 없습니다.  2. HTTP Method에 대해 설명해 주세요. :  GET, POST, PUT, DELETE가 있습니다.  GET은 클라이언트에서 서버로 어떠한 리소스로부터 정보를 요청하기 위해 사용되는 메소드입니다. 서버에서 어떤 데이터를 보여줄 때 값, 내용, 상태들을 바꾸지 않을 경우에 사용됩니다. 또한, 데이터가 헤더에 추가되어 전송되므로 URL에 데이터가 노출되기 때문에, 보안적으로 중요한 데이터는 포함시켜서는 안됩니다.  POST는 리소스를 생성,업데이트하기 위해 서버에 데이터를 보내는 데 사용하는 메소드 입니다. 즉, 서버상의 데이터 값이나 상태를 바꿀 때 사용됩니다. 또한 GET과는 달리 데이터를 바디에 추가여 전송하기 때문에, 완잔하게 안전한 것은 아니지만 조금 더 안전합니다.  GET과 POST의 차이점으로는 GET요청은 캐시가 되며 멱등성이 보장되지만, POST요청은 캐시가 되지 않고 멱등성이 보장되지 않습니다. 3. HTTP의 주요 상태코드에 대해 설명해 주세요. :  200 : OK, 요청이 성공적으로 처리되었습니다. 요청에 따른 응답을 반환합니다.  404 : 서버는 요청받은 리소스를 찾을 수 없습니다. 예를 들어, 브라우저에서는 알려지지 않은 URL을 의미합니다.  503 : 서버가 요청을 처리할 준비가 되지 않은것을 의미합니다. 일반적인 원인은 유지보수를 위해 작동이 중단되거나, 과부하가 걸린 서버일 경우 발생할 수 있습니다. 또한 1번 대 부터 5번 대 상태 코드의 대략적인 의미는 다음과 같습니다.  1xx (정보) : 요청을 받았으며 프로세스가 계속 진행합니다.  2xx (성공) : 요청을 성공적으로 받았으며 인식했고 수용합니다.  3xx (리다이렉션) : 요청을 위한 추가 작업 조치가 필요합니다.  4xx (클라이언트 오류) : 요청의 문법이 잘못되었거나 요청을 처리할 수 없습니다.  5xx (서버 오류) : 서버가 명백히 유효한 요청에 대한 충족을 실패했습니다. 4. 쿠키(Cookie)와 세션(Session)의 차이점에 대해 말해 주세요. :  쿠키는 사용자의 컴퓨터에 저장하는 작은 기록 정보 파일입니다. HTTP에서 클라이언트의 상태 정보를 PC에 저장했다가 필요시 정보를 참조하거나 재사용할 수 있습니다.  세션은 일정 시간동안 같은 사용자로부터 들어오는 일련의 요구를 하나의 상태로 보고, 그 상태를 유지시키는 기술입니다. 즉, 방문자가 웹 서버에 접속해 있는 상태를 하나의 단위로 보고 그것을 세션이라고 합니다. 5. https://www. google. com/에 접속할 때 생기는 과정에 대해 설명해 주세요. (웹 동작 방식 이해): 이미지 2. 웹 동작 방식 이해  사용자가 브라우저에 URL(https://www. google. com/)을 입력 브라우저는 DNS를 통해 서버의 진짜 주소를 찾음 HTTP 프로토콜을 사용하여 HTTP 요청 메세지를 생성함 TCP/IP 연결을 통해 HTTP요청이 서버로 전송됨 서버는 HTTP 프로토콜을 활용해 HTTP 응답 메세지를 생성함 TCP/IP 연결을 통해 요청한 컴퓨터로 전송 도착한 HTTP 응답 메세지는 웹페이지 데이터로 변환되고, 웹 브라우저에 의해 출력되어 사용자가 볼 수 있게 됨 6. TCP와 UDP의 차이를 설명해 주세요. :  TCP는 연결형 서비스로 3-way handshaking 과정을 통해 연결을 설정하기 때문에 높은 신뢰성을 보장하지만, 속도가 비교적 느리다는 단점이 있습니다. (1:1 통신방식) UDP는 비연결형 서비스로 3-way handshaking을 사용하지 않기 때문에 신뢰성이 떨어지는 단점이 있지만, 데이터 수신 여부를 확인하지 않기 때문에 속도가 빠르다는 장점이 있습니다. (1:1 or 1:N or N:N 통신방식) 6-1. 그렇다면 3 way-handshake와 4 way-handshake를 설명해 주세요. :  3 way-handshake란 TCP 네트워크에서 통신 하는 장치가 서로 연결이 잘 되었는지 확인하는 방법입니다. 송신자와 수신자는 총 3번에 걸쳐 데이터를 주고 받으며 통신이 가능한 상태인지 확인합니다.  4 way-handshake란 TCP 네트워크에서 통신 하는 장치의 연결을 해제하는 방법입니다. 송신자와 수신자는 총 4번에 걸쳐 데이터를 주고 받으며 연결을 끊습니다. 7. OSI 7 layer와 각 계층에 대해 아는대로 설명해 주세요. : 이미지 3. OSI 7 layer OSI7계층은 네트워크 통신을 구성하는 요소들 7개의 계층으로 표준화 한 것입니다. 이렇게 표준화하는 것의 장점은 통신이 일어나는 과정을 단계별로 파악할 수 있어, 문제가 발생하면 해당 문제를 해결하기 용이해집니다.  7 계층(응용 계층) : 사용자에게 통신을 위한 서비스 제공. 인터페이스 역할 6 계층(표현 계층) : 데이터의 형식(Format)을 정의하는 계층 (코드 간의 번역을 담당) 5 계층(세션 계층) : 컴퓨터끼리 통신을 하기 위해 세션을 만드는 계층 4 계층(전송 계층) : 최종 수신 프로세스로 데이터의 전송을 담당하는 계층 (단위 :Segment) (ex. TCP, UDP) 3 계층(네트워크 계층) : 패킷을 목적지까지 가장 빠른 길로 전송하기 위한 계층 (단위 :Packet) (ex. Router) 2 계층(데이터링크 계층) : 데이터의 물리적인 전송과 에러 검출, 흐름 제어를 담당하는 계층 (단위 :frame) (ex. 이더넷) 1 계층(물리 계층) : 데이터를 전기 신호로 바꾸어주는 계층 (단위 :bit) (장비: 케이블,리피터,허브) 8. 세션 기반 인증과 토큰 기반 인증의 차이에 대해 얘기해 주세요. : 세션 기반 인증은 클라이언트로부터 요청을 받으면 클라이언트의 상태 정보를 저장하므로 Stateful한 구조를 가지고, 토큰 기반 인증은 상태 정보를 서버에 저장하지 않으므로 Stateless한 구조를 가집니다.  Stateful이란 server side에 client와 server의 동작, 상태정보를 저장하는 프로토콜이며 세션 상태에 기반하여 server의 응답이 달라집니다. 즉, Stateful은 세션이 종료될 때까지 클라이언트의 세션 정보를 저장하는 네트워크 프로토콜입니다. Stateless이란 server side에 client와 server의 동작, 상태정보를 저장하지 않는 프로토콜이며 server의 응답이 client와의 세션 상태와 독립적입니다. 즉 Stateless는 서버가 클라이언트의 세션 상태 및 세션 정보를 저장하지 않는 네트워크 프로토콜입니다.  8-1. 그렇다면 Stateful한 세션 기반의 인증 방식을 사용하게 된다면 어떠한 단점이 있을까요?:  서버에 세션을 저장하기 때문에 사용자가 증가하면 서버에 과부하를 줄 수 있어 확장성이 낮습니다.  해커가 훔친 쿠키를 이용해 요청을 보내면 서버는 올바른 사용자가 보낸 요청인지 알 수 없습니다. 8-2. JWT(Json Web Token)에 대해 설명해 주세요. : JWT란 JSON 포맷을 이용해 사용자에 대한 속성을 저장하는 Claim 기반의 웹 토큰이며, 토큰 자체를 정보로 사용하는 Self-Contained(자가수용적-JWT는 필요한 모든 정보를 자체적으로 가지고 있음) 방식으로 정보를 안전하게 전달합니다. JWT는 각 파트를 . 으로 구분하여 헤더(Header). 내용(Payload). 서명(Signature) 형식으로 구성됩니다.  Clame이란 사용자에 대한 프로퍼티나 속성을 뜻합니다.  9. RESTful에 대해 설명해 주세요. : 우선 REST란, HTTP URI(Uniform Resource Identifier)를 통해 자원(Resource)을 명시하고, HTTP Method(POST, GET, PUT, DELETE)를 통해 해당 자원에 대한 CRUD Operation을 적용하는 것을 의미합니다. REST 기반으로 서비스 API를 구현한 것을 REST API라고 하며, 이러한 ‘REST API’를 제공하는 웹 서비스를 ‘RESTful’하다고 할 수 있습니다.  9-1. 그렇다면, RESTful하지 못한 경우는 어떤 것인가요?: CRUD 기능을 모두 POST로만 처리하는 API같은 경우 또는 route에 resource, id 외의 정보가 들어가는 경우 등이 있습니다. REST는 조금더 깊게 공부하시기를 추천드립니다. 명확한 표준이 존재하지 않는다는 점 또한 RESTful을 완전히 만족하는 API를 만들기는 생각보다 까다롭습니다. 자세한 공부를 원하신다면 🌎REST란? REST API란? RESTful이란?의 포스트를 확인해주세요. &lt;/font&gt; 🔎 개발 면접 질문 - 운영체제: 1. 프로세스와 스레드의 차이를 설명해 주세요. :  프로세스는 실행중인 프로그램을 의미합니다. 완벽히 독립적이기 때문에 메모리 영역(Code, Data, Heap, Stack)을 다른 프로세스와 공유하지 않습니다. 프로세스는 최소 1개의 쓰레드를 가지고 있습니다.  스레드는 실행 제어만 분리한 것을 의미합니다. 프로세스 내에서 Stack만 따로 할당 받고, 그 이외의 메모리 영역(Code, Data, Heap)영역을 공유하기 때문에 다른 쓰레드의 실행 결과를 즉시 확인할 수 있습니다. 쓰레드는 프로세스 내에 존재하며 프로세스가 할당받은 자원을 이용하여 실행됩니다. 2. 멀티 프로세스와 멀티 스레드의 특징에 대해 설명해 주세요. :  멀티 프로세스는 하나의 프로세스가 죽어도 다른 프로세스에 영향을 끼치지 않고 계속 실행된다는 장점이 있지만 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지한다는 단점이 있습니다.  멀티 스레드는 멀티 프로세스보다 적은 메모리 공간을 차지하고 문맥 전환이 빠르다는 장점이 있지만 하나의 스레드에 문제가 생기면 전체 쓰레드가 영향을 받으며 동기화 문제도 있다는 단점이 있습니다. 또한, 다수의 쓰레드가 공유 데이터에 동시에 접근하는 경우에 상호배제 또는 동기화 기법을 통해 동시성 문제 또는 교착 상태가 발생하지 않도록 주의해야 합니다. 3. 멀티 스레드 프로그래밍에 대해 설명해 주세요. : 멀티 스레드 프로그래밍은 하나의 프로세스에서 여러개의 스레드를 만들어 자원의 생성과 관리의 중복을 최소화하는 것을 멀티 스레드 프로그래밍이라고 합니다. 장점  멀티 프로세스에 비해 메모리 자원소모가 줄어듭니다.  힙 영역을 통해서 스레드간 통신이 가능해서 프로세스간 통신보다 간단합니다.  스레드의 컨텍스트 스위칭은 프로세스의 컨텍스트 스위칭보다 빠릅니다. 단점 힙 영역에 있는 자원을 사용할 때는 동기화를 해야합니다.  동기화를 위해서 락을 과도하게 사용하면 성능이 저하될 수 있습니다.  하나의 스레드가 비정상적으로 동작하면 다른 스레드도 종료될 수 있습니다. 3-1. 멀티 프로세스 or 멀티 스레드 프로그래밍을 해본 경험이 있나요?: 저는 🌎Python GIL, Global interpreter Lock을 공부하기 위해 멀티 스레딩을 경험해 본 적이 있습니다. 이 문제는 지원자분이 멀티 프로세스 or 멀티 스레드를 구현해본 경험을 이야기 하시면 될 것 같습니다.  4. 컨텍스트 스위칭(Context Switching)에 대해 설명해 주세요. : 컨텍스트 스위칭(Context Switching)은 한 Task가 끝날 때까지 기다리는 것이 아니라 여러 작업을 번갈아가며 실행해서 동시에 처리될 수 있도록 하는 방법입니다. 인터럽트가 발생하면 현재 프로세스의 상태를 PCB에 저장하고 새로운 프로세스의 상태를 레지스터에 저장하는 방식으로 동작합니다. 이 때, CPU는 아무런 일을 하지 않으므로 잦은 컨텍스트 스위칭은 성능저하를 일으킬 수 있습니다. 스레드와 프로세스의 동작방식이 약간 상이한데, 스레드는 캐시메모리나 PCB에 저장해야하는 내용이 적고, 비워야 하는 내용도 적기때문에 상대적으로 더 빠른 컨텍스트 스위칭이 일어날 수 있습니다.  5. 동기와 비동기의 차이에 대해 설명해 주세요. : 동기는 순차적, 직렬적으로 테스크를 수행하고, 비동기는 병렬적으로 테스크를 수행합니다. 예를 들어, 서버에서 데이터를 가져와서 화면에 표시하는 작업을 수행할 때, 동기는 서버에 데이터를 요청하고 데이터가 응답될 때까지 이후 테스크들은 블로킹(Blocking, 작업 중단)됩니다. 비동기는 서버에 데이터를 요청한 이후 서버로부터 데이터가 응답될 때까지 대기하지 않고(Non-Blocking) 즉시 다음 테스크를 계속해 수행합니다.  6. 데드락(DeadLock)이 무엇인가요?: 데드락(DeadLock) 또는 교착상태란 한정된 자원을 여러 프로세스가 사용하고자 할 때 발생하는 상황으로, 프로레스가 자원을 얻기 위해 영구적으로 기다리는 상태입니다. 예를 들어 다음과 같은 상황에서 데드락이 발생할 수 있습니다. 자원 A를 가진 프로세스 P1과 자원 B를 가진 프로세스 P2가 있을 때, P1은 B를 필요로 하고 P2는 A를 필요로 한다면 두 프로세스 P1, P2는 서로 자원을 얻기위해 무한정 기다리게 됩니다.  이미지 4. DeadLock 7. 뮤텍스(Mutex)와 세마포어(Semaphore)의 차이에 대해 설명해 주세요. : 세마포어는 여러개의 프로세스가 접근 가능한 공유자원을 관리하는 방식이고, 뮤텍스가 될 수 있지만, 뮤텍스는 한 번에 한 개의 프로세스만 접근 가능하도록 관리하는 방식입니다. 따라서 뮤텍스는 세마포어가 될 수 없습니다. 또, 세마포어는 다른 프로세스가 세마포어를 해제할 수 있지만, 뮤텍스는 락을 획득한 프로세스만 락을 반환할 수 있습니다.  8. 가상 메모리와 페이지 폴트에 대해 설명해 주세요. : 가상메모리는 RAM의 부족한 용량을 보완하기 위해, 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 할당하는 방식입니다. OS는 프로세스들의 내용(페이지) 중에서 덜 중요한 것들을 하드디스크에 옮겨 놓고, 관련 정보를 페이지 테이블에 기록합니다. CPU는 프로세스를 실행하면서 페이지 테이블을 통해 페이지를 조회하는데, 실제메모리에 원하는 페이지가 없는 상황이 발생할 수 있습니다. 이것을 페이지 폴트라고 하는데 프로세스가 동작하면서 실제메모리에 필요한 데이터(페이지)가 없으면 가상메모리를 통해서 해당 데이터를 가져오게 됩니다. 가상메모리는 하드디스크에 저장되어 있기 때문에, 페이지폴트가 발생하면 I/O에 의한 속도의 저하가 발생합니다.  9. 페이지 교체 알고리즘에 대해 설명해주세요. : 페이지를 교체하는 이유는 가상메모리를 통해 조회한 페이지는 다시 사용될 가능성이 높기 때문입니다. 페이지 교체를 위해서는 실제메모리에 존재하는 페이지를 가상메모리로 저장한 후에, 가상메모리에서 조회한 페이지를 실제메모리로 로드해야 됩니다. 이 때 사용되어지는 알고리즘을 페이지 교체 알고리즘이라고 합니다. 아래는 대표적인 페이지 교체 알고리즘 입니다.  FIFO(First In First Out) : FIFO 알고리즘은 메모리에 올라온 지 가장 오래된 페이지를 교체합니다. 간단하고, 초기화 코드에 대해 적절한 방법이며, 페이지가 올라온 순서를 큐에 저장합니다.  LRU(Least Recently Used) : LRU 알고리즘은 실제메모리의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지를 선택하는 방식입니다.  추가로 참조 횟수가 가장 작은 페이지를 교체하는 알고리즘인 LFU(Least Frequently Used)와 참조 횟수가 가장 많은 페이지를 교체하는 알고리즘인 MFU(Most Frequently Used)가 있는데 구현에 상당한 비용이 들고, 최적 페이지 교체 정책을 제대로 LRU만큼 유사하게 구현해내지 못하기 때문에 실제로는 잘 사용 되어지지 않습니다.  끝맺음 공부를 하면서 질문에 괜찮은 내용이 있으면 요약하면서 계속 추가하고 있습니다. 또한, 기본적인 이론에 대해 다시 공부를 하려고 정리한 내용이기 때문에 잘못된 부분들이 있을 수도 있습니다. 잘못된 정보가 보이거나, 부족한 내용, 추가되면 좋을 것 같은 내용이 있다면 댓글에 적어주시면 감사하겠습니다!😊 [참고자료]  JSON Web Token 이 뭘까? https://smjeon. dev/etc/interview-question/ minsgy-백엔드 개발자 [면접/학습내용]"
    }, {
    "id": 17,
    "url": "http://localhost:4000/mysql-error2/",
    "title": "(문제해결)You do not have the SUPER privilege and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable)",
    "body": "2022/07/01 -  💡 Intro: MySQL을 사용하는중에 특정 테이블에 트리거를 생성했는데, You do not have the SUPER privilege and binary logging is enabled (you *might* want to use the less safe log_bin_trust_function_creators variable)라는 에러가 발생했습니다. 구글에서 정보를 찾아보니 계정에 권한이 없으니 log_bin_trust_function_creators variable의 설정을 변경해야 한다고 합니다.  🔎 RDS log_bin_trust_function_creators: log_bin_trust_function_creators 옵션은 MySQL이 함수를 수정 및 생성에 대한 제약을 강제할 수 있는 기능입니다. 해당 옵션의 default는 0(OFF)이며, OFF상태의 경우 권한이 있더라도 trigger를 생성할 수 없고, function을 생성할 수 없습니다. SUPER 권한이 있는 사용자만이 함수를 생성 및 변경할 수 있다고 합니다. 또한 log_bin_trust_function_creators 옵션을 1(ON)로 설정한 경우에는 함수 생성에 제약을 받지 않습니다.  📚 AWS RDS 파라미터 그룹 변경하기: 📕 1. log_bin_trust_function_creators 옵션 변경하기: AWS RDS의 파라미터 그룹으로 들어가 줍니다. 그리고 변경할 파라미터 그룹의 이름을 클릭합니다.   그리고 파리미터 편집으로 log_bin_trust_function_creators에 0(OFF)으로 되어져있는 옵션의 값을 1로 변경해줍니다.   📘 2. 데이터베이스 파라미터 그룹 변경: AWS RDS의 데이터베이스에 들어갑니다. 그리고 우측의 수정을 클릭합니다.   추가 구성의 데이터베이스 옵션으로 가서 DB파라미터 그룹을 default에서 위에서 설정한 그룹으로 변경합니다. 그리고 맨 밑의 DB인스턴스 수정을 클릭하면 수정됩니다.   [참고자료]  https://aws. amazon. com/ko/premiumsupport/knowledge-center/rds-mysql-functions/"
    }, {
    "id": 18,
    "url": "http://localhost:4000/python-gil/",
    "title": "Python GIL, Global interpreter Lock",
    "body": "2022/06/16 -  💡 Intro: 오늘은 Python의 가장 큰 특징중 하나인 GIL(Global interpreter Lock)에 대해 알아보려고 합니다. Python을 사용하는 개발자라면 누구나 다 한번쯤은 들어봤을 것이고, 저 또한 GIL에 대해 공부해 본적이 있지만 다시 한번 정리해 보려고 합니다.  🔎 Python 인터프리터란?: 우선 GIL이란 Global Interpreter Lock의 약자로 파이썬 인터프리터가 한 쓰레드만이 하나의 바이트코드를 실행 시킬 수 있도록 해주는 Lock입니다. 즉, Python 인터프리터는 한 번에 한 쓰레드만 실행될 수 있다는 것을 의미합니다.  그렇다면 파이썬 인터프리터란 무엇일까요? Python 인터프리터란, Python으로 작성된 코드를 한 줄씩 읽으면서 실행하는 프로그램을 뜻 합니다. Python 인터프리터에 대한 자세한 내용은 파이썬은 인터프리터언어입니까? 블로그에서 조금 더 심도깊게 생각해보실 수 있습니다.  🔎 GIL(Global Interpreter Lock): GIL (Global Interpreter Lock)을 🌎Python 위키에서는 다음과 같이 정의하고 있습니다.  In CPython, the global interpreter lock, or GIL, is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. The GIL prevents race conditions and ensures thread safety. A nice explanation of 🌎how the Python GIL helps in these areas can be found here. In short, this mutex is necessary mainly because CPython’s memory management is not thread-safe.  해석을 해보면, Python의 객체들에 대한 접근을 보호하는 일종의 Mutex로서 여러 개의 쓰레드가 파이썬 코드를 동시에 실행하지 못하도록 하는 것을 의미합니다. 즉, 한 프로세스 내에서 Python 인터프리터는 한 시점에 하나의 쓰레드에 의해서만 실행될 수 있습니다. 멀티 쓰레딩이 불가능하다는 것이 아니나, 원래 멀티 코어라면 멀티 쓰레딩 시에 여러 개의 쓰레드가 여러 코어 상에서 병렬실행될 수 있는데, Python에서는 그러한 병렬 실행이 불가능하다는 것입니다.  간단하게 설명을 해보자면, 3개의 쓰레드를 통해 작업을 한다고 가정했을 때 하나의 쓰레드에 모든 자원을 허락하고 그 후에는 Lock을 걸어 다른 스레드는 실행할 수 없게 막아버림으로써, 각각의 쓰레드는 GIL을 얻고 동작하지만 이 때 다른 쓰레드는 모두 동작을 멈추게 됩니다. 이를 그림으로 나타내면 다음과 같습니다.   🔎 그럼 GIL이 왜 생긴걸까?: Python에서 모든 것은 객체(Object)입니다. 그리고 각 객체는 Reference Count를 저장하기 위한 필드를 가지고 있습니다.  Reference Count란 그 객체를 가리키는 Reference가 몇 개 존재하는지를 나타내는 것으로, Python에서의 GC(Garbage Collection)는 이러한 Reference Count가 0이 되면 해당 객체를 메모리에서 삭제시키는 메커니즘으로 동작하고 있습니다.  따라서 파이썬의 모든 객체는 Reference count, 즉 해당 변수가 참조된 수를 저장하고 있습니다. 여기서 문제가 발생하게 되는데, 멀티 쓰레드인 경우 여러 쓰레드가 하나의 객체를 사용한다면 Reference count를 관리하기 위해서 모든 객체에 대한 lock이 필요할 것입니다.  이러한 비효율을 막기 위해서 Python에서 GIL을 사용하게 되었습니다. 그 당시 GIL을 선택해야 했던 이유는 🌎What Is the Python Global Interpreter Lock (GIL)? 에서 찾을 수 있었습니다.  Python has been around since the days when operating systems did not have a concept of threads. Python was designed to be easy-to-use in order to make development quicker and more and more developers started using it. A lot of extensions were being written for the existing C libraries whose features were needed in Python. To prevent inconsistent changes, these C extensions required a thread-safe memory management which the GIL provided. The GIL is simple to implement and was easily added to Python. It provides a performance increase to single-threaded programs as only one lock needs to be managed. C libraries that were not thread-safe became easier to integrate. And these C extensions became one of the reasons why Python was readily adopted by different communities. As you can see, the GIL was a pragmatic solution to a difficult problem that the CPython developers faced early on in Python’s life.  📚 그렇다면 Python 멀티쓰레딩은 무조건 느릴까?: CPU 연산의 비중이 큰 작업을 할 때, Context Switching으로 인해 괜한 Cost만 잡아먹기 때문에 멀티 쓰레딩은 오히려 성능을 떨어뜨리게 됩니다. 하지만 I/O, Sleep 등의 외부 연산을 하느라 CPU가 아무것도 하지 않고 기다리기만 할 때는 다른 쓰레드로 Context Switching을 하게 됩니다.  그러한 이유로 CPU 연산의 비중이 적은 I/O, Sleep 등의 외부 연산 같이 비중이 큰 작업을 할 때는 멀티 쓰레딩이 굉장히 좋은 성능을 보여주게 됩니다. 즉, Python 멀티쓰레딩은 무조건 느리다라는 말은 맞는 말이 아닙니다. 다음 예시를 통해 설명이 가능합니다.  123456789101112131415161718192021222324252627282930313233343536import randomimport threadingimport timedef working():  time. sleep(1)  max([random. random() for i in range(10000000)])  time. sleep(1)  max([random. random() for i in range(10000000)])  time. sleep(1)# Single Threads_time = time. time()working()working()e_time = time. time()print(f'{e_time - s_time:. 5f}')# Multi Threads_time = time. time()threads = []for i in range(2):  threads. append(threading. Thread(target=working))  threads[-1]. start()for t in threads:  t. join()e_time = time. time()print(f'{e_time - s_time:. 5f}') 아래와 같이 확연한 차이를 볼 수 있습니다.  12345Single Thread -&gt; 10. 77272Multi Thread -&gt; 7. 17564 Single Thread는 sleep으로 인해 아무 것도 못하고 동작을 대기하게 되고, Multi Thread는 sleep으로 멈춘 상태에서 다른 스레드로 Context Switching하여 Single Thread의 효율을 개선하게 됩니다.   끝맺음Python으로 작업하는 개발자의 입장으로써 지금까지는 GIL로 인한 불편한점은 느낄 수 없었습니다. 하지만 뜻하지 않은 계기로 오랜만에 다시 GIL(Global Interpreter Lock)을 공부하게 되었는데, GIL에 대한 역사와 Python의 GC에 대해 충분히 이해할 수 있었던것 만으로도 매우 의미있는 시간이었다고 생각합니다. 😊 [참고자료]  파이썬은 인터프리터언어입니까? 파이썬이 마침내 ‘GIL’을 제거할 수 있을까? Python 위키 왜 Python에는 GIL이 있는가 Davie Beazley의 Understanding the Python GIL"
    }, {
    "id": 19,
    "url": "http://localhost:4000/mysql-error1/",
    "title": "(문제해결)ERROR 1227 (42000) at line 18 - Access denied; you need (at least one of) the SUPER privilege(s) for this operation",
    "body": "2022/06/04 -  💡 Intro: MySQL에서 DB의 백업파일을 import하려는데 다음과 같은 ERROR 1227 (42000) at line 18 - Access denied; you need (at least one of) the SUPER privilege(s) for this operation라는 에러가 발생했습니다.  📚 해결방법: 구글에서 정보를 찾아보니 프로시저의 DEFINER 때문이었는데, RDS가 제공하는 MySQL 서버가 사용자가 아닌 다른 DEFINER가 지정된 sql 파일을 허용하지 않기 때문이라고 합니다. 즉, DEFINER의 계정으로 import하지 않아서 생기는 문제였습니다.  해결방법은 너무 간단했습니다. 그냥 definer를 삭제하여 import시키면 기본 definer로 자동으로 설정이 된다고 합니다,.  모조리 삭⭐️제⭐️ jjomnoon블로그님의 말대로 찾을 내용에 DEFINER=DEFINER=root@localhost, 바꿀내용에 공백을 입력하여 전부 삭제하여 해결했습니다.  [참고자료]  jjomnoon블로그 https://m. blog. naver. com/tpgpfkwkem0/221997595407 stackoverflow-questions"
    }, {
    "id": 20,
    "url": "http://localhost:4000/content-type/",
    "title": "form-data? x-www-form-urlencoded? raw?",
    "body": "2022/05/17 -  💡 Intro: Postman을 사용하다 보면 여러 가지의 Content-Type이 있습니다. form-data, x-www-form-urlencoded, Raw, Binary, GraphQL이 있는데, 오늘은 이 요청 유형에 대해 알아보려 합니다.  🔎 들어가기전 Content-Type이란?: 📝 Content-Type :  API 연동시에, 보내는 자원의 형식을 명시하기 위해서 HTTP Header에 실리는 정보를 content-type이라고 합니다. 즉, api 요청 시 request에 실어 보내는 data의 type정보를 표현합니다.  content-type에 대한 자세한 정보는 NAMP 님의 HTTP Content-Type 정리에 잘 정리되어져 있으니 정보가 필요하신분은 방문해주세요! 📚 POST 요청 유형: 📕 1. form-data(양식 데이터): 이름에서 알 수 있듯이 양식 데이터는 양식을 채울때 입력 한 세부 정보와 같이 양식 내부에 래핑하는 데이터를 보내는데 사용됩니다. 이러한 세부 정보는 Key가 보내는 항목의 “이름” 이고 Value는 실제 값을 입력하면 됩니다. 즉, Key-Value 쌍으로 작성하여 전송됩니다.   또한, 텍스트 뿐만아니라 파일과 함께 일부 데이터를 서버에 전송하기를 원한다면 아래 GIF와 같이 form-data에서 수행할 수도 있습니다.   📘 2. x-www-form-urlencoded: 요즘은 많이 사용하지는 않지만 종종 사용하는 방식입니다. form-data와 거의 동일한 목적으로 사용되며 form-data와 상당히 유사합니다. form-data와의 차이점은 x-www-form-urlencoded는 보내는 데이터를 URL인코딩 이라고 부르는 방식으로 인코딩 후에 웹서버로 보냅니다. 또한, Raw는 본문 메시지가 요청 본문을 나타내는 비트스트림(bitstream)으로 표시됨을 의미합니다. 이러한 비트는 문자열 서버로 해석됩니다.   📒 3. raw: 이름 그대로 날것이라고 해석할 수 있습니다. raw를 제외한 다른 타입들의 경우 각각 용도에 맞게 Postman에서 알아서 처리를 해줍니다. 하지만 raw타입은 문자 그대로를 보내기 때문에 개발자가 요청 형식에 맞게끔 값을 써주어야 합니다.   raw를 선택하면 위 사진과 같이 세부 항목을 선택할 수 있습니다. Text, JavaScript, JSON, HTML, XML의 형식을 지원합니다. 물론 형식에 틀리게 작성한다면 틀렸다고 알려줍니다.  📗 4. binary: Binary는 수동으로 입력할 수 없는 형식으로 데이터를 전송하도록 설계되었습니다. 컴퓨터의 모든 것이 바이너리로 변환되기 때문에 이미지, 파일 등과 같이 수동으로 작성할 수 없는 상황일 때 이러한 옵션을 사용합니다. 즉, 텍스트 없이 이미지나 영상, 오디오 파일 등을 보낼 때 사용합니다.   📙 5. GraphQL: GraphQL이란 Facebook에서 만든 어플리케이션 레이어 쿼리 언어라고 합니다. 웹 클라이언트가 서버로부터 데이터를 효율적으로 가져오기 위한 언어입니다. GraphQL은 GraphQL 개념잡기에서 더 자세하게 보실 수 있습니다.   끝맺음이렇게 오늘은 여러 가지의 요청 유형에 대해 알아보았습니다. 저는 실제로 사용할 때 JSON의 요청이 많다 보니, raw와 form-data를 가장 많이 사용하게 되더군요. 평소에는 생각지도 못한 부분들이었는데, 갑자기 이것들에 대한 차이가 뭐지. . ? 라는 생각을 가지게 되었고, 그렇게 이번에 공부를 하며 자료를 정리하다보니 생각보다 흥미로운 부분들이 많았던 것 같습니다. 😊 [참고자료]  HTTP Content-Type 정리 https://jw910911. tistory. com/117 Postman을 사용한 POST 요청 (GraphQL) GraphQL 개념잡기"
    }, {
    "id": 21,
    "url": "http://localhost:4000/jquery-btn-event/",
    "title": "jQuery로 버튼 클릭 이벤트 만들기",
    "body": "2022/05/09 -  💡 Intro:  저번에 포스팅한 모달창 위에서 진행됩니다! 오늘은 버튼을 클릭했을 때 클릭되는 효과와 클릭한 데이터가 입력되고 지워지는 기능을 만들어 보려고 합니다.  모달창 생성법은 자바스크립트 예쁜 모달창 만들기포스트를 확인해주세요! 📚 버튼클릭이벤트 만들기: 📕 1. CSS로 버튼 이미지 만들기: 📝 CSS 12345678910111213141516171819202122232425. btn-event {  margin: 20px;  position: relative;  border: none;  display: inline-block;  padding: 15px 30px;  border-radius: 15px;  font-family:  paybooc-Light , sans-serif;  box-shadow: 0 15px 35px rgba(0, 0, 0, 0. 2);  text-decoration: none;  font-weight: 600;  font-size: medium;  transition: 0. 25s;  box-sizing: border-box;  background-color: #77af9c;  color: #ffffff;}  button. on {    color: white;    font-size: large;    background-color: #275f4d;  }  transition는 CSS 프로퍼티의 값이 변화할 때, 프로퍼티 값의 변화가 일정 시간(duration)에 걸쳐 일어나도록 하게합니다. 저는 버튼이 변화할 때 조금 더 부드러운 모션을 주기위해 transition: 0. 25s;로 설정했습니다.  button. on : 보통 button:hover을 사용하는데, 저는 후에 javascript로 addClass( on );로 이벤트를 주기위해 button. on을 사용했습니다. 🔮 결과(gif):  📘 2. HTML작성하기: 작성한 css와 javascript로 모달창 코드를 작성합니다. 그리고 모달창을 켜기위한 버튼을 생성합니다.  📝 HTML 전체 메인코드 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;!--모달창--&gt;&lt;div class= modal-dim js-modal &gt;  &lt;div class= dim-bg &gt;&lt;/div&gt;  &lt;div class= modal-layer &gt;    &lt;div class= modal-top &gt;      &lt;div class= modal-tit &gt;버튼 이벤트 동작하기&lt;/div&gt;      &lt;button type= button  class= modal-close js-modal-close &gt;&lt;/button&gt;    &lt;/div&gt;        &lt;div class= modal-top  style= height:100px &gt;      &lt;textarea id= select_button_text  placeholder=             class= inp-frm js-count  data-count= 400  readonly&gt;&lt;/textarea&gt;    &lt;/div&gt;    &lt;div class= modal-container &gt;      &lt;div class=  &gt;        &lt;div class= board &gt;          &lt;div class= tit-menu &gt;버튼 이벤트 동작하기&lt;/div&gt;          &lt;div class= frm-line-v2 &gt;&lt;/div&gt;          &lt;div class= frm-area  id= btn-button &gt;            &lt;button class= btn-event  id= button_1  value= id_1 &gt;1&lt;/button&gt;            &lt;button class= btn-event  id= button_2  value= id_2 &gt;2&lt;/button&gt;            &lt;button class= btn-event  id= button_3  value= id_3 &gt;3&lt;/button&gt;            &lt;button class= btn-event  id= button_4  value= id_4 &gt;4&lt;/button&gt;            &lt;button class= btn-event  id= button_5  value= id_5 &gt;5&lt;/button&gt;            &lt;button class= btn-event  id= button_6  value= id_6 &gt;6&lt;/button&gt;            &lt;button class= btn-event  id= button_7  value= id_7 &gt;7&lt;/button&gt;            &lt;button class= btn-event  id= button_8  value= id_8 &gt;8&lt;/button&gt;            &lt;button class= btn-event  id= button_9  value= id_9 &gt;9&lt;/button&gt;            &lt;button class= btn-event  id= button_10  value= id_10 &gt;10&lt;/button&gt;            &lt;button class= btn-event  id= button_11  value= id_11 &gt;11&lt;/button&gt;            &lt;button class= btn-event  id= button_12  value= id_12 &gt;12&lt;/button&gt;            &lt;button class= btn-event  id= button_13  value= id_13 &gt;13&lt;/button&gt;            &lt;button class= btn-event  id= button_14  value= id_14 &gt;14&lt;/button&gt;            &lt;button class= btn-event  id= button_15  value= id_15 &gt;15&lt;/button&gt;            &lt;button class= btn-event  id= button_16  value= id_16 &gt;16&lt;/button&gt;          &lt;/div&gt;        &lt;/div&gt;      &lt;/div&gt;    &lt;/div&gt;  &lt;/div&gt;&lt;/div&gt;&lt;!--모달창 켜기위한 버튼--&gt;&lt;div&gt;  &lt;div&gt;모달창 만들기&lt;/div&gt;  &lt;div&gt;    &lt;div style= float:left; width:20%; &gt;      &lt;input type= button  value= modal_test  id= modal_test &gt;    &lt;/div&gt;  &lt;/div&gt;&lt;/div&gt; 📒 3. Javascript작성하기: Javascript로 버큰 끄고/키기 이벤트와 텍스트가 입력되고 지워지는 코드를 작성합니다.  📝 HTML 전체 메인코드 1234567891011121314151617181920212223242526272829303132333435363738394041$(function () {  let check = {        checked_cnt1 : 0, checked_cnt2 : 0, checked_cnt3 : 0,         checked_cnt4 : 0, checked_cnt5 : 0, checked_cnt6 : 0,         checked_cnt7 : 0, checked_cnt8 : 0, checked_cnt9 : 0,         checked_cnt10 : 0, checked_cnt11 : 0, checked_cnt12 : 0,         checked_cnt13 : 0, checked_cnt14 : 0, checked_cnt15 : 0,         checked_cnt16 : 0, checked_cnt17 : 0, checked_cnt18 : 0,         checked_cnt19 : 0, checked_cnt20 : 0, checked_cnt21 : 0,         checked_cnt22 : 0, checked_cnt23 : 0, checked_cnt24 : 0,         checked_cnt25 : 0, checked_cnt26 : 0, checked_cnt27 : 0,         checked_cnt28 : 0, checked_cnt29 : 0, checked_cnt30 : 0        }  $( [id^=button_] ). click(function(){    var cnt = $(this). attr( id ). substr(7)        if(check['checked_cnt'+cnt] == 0){      check['checked_cnt'+cnt] = 1      $(this). addClass( on );      $('#select_button_text'). append($(this). attr('value') + ',');      $('#button'). append($(this). attr('value') + ',');    }else{      check['checked_cnt'+cnt] = 0      $(this). removeClass( on );      button_text = $('#select_button_text'). val();      button_text = button_text. replace($(this). attr('value') + ',', '')      $( #select_button_text ). text(button_text);      $( #button ). text(button_text);    }  });})  먼저 동적으로 변수를 할당시켜주고 싶었으나, javascript에서는 찾지를 못해 let check = {}로 Dict형태로 변수들을 0값으로 할당해주었습니다. (좋은 방법이 있으면 댓글로 남겨주세요. 😥) [id^=button_]는 button으로 시작하는 모든 id의 값을 불러오기위해서 사용했습니다. 자세한 내용은 jQuery 정규식 [id^=] 사용해보기에서 확인해 주세요! var cnt = $(this). attr( id ). substr(7)는 id의 끝에 붙어있는 숫자를 불러오기위해서 사용했습니다. (예시 - button_15. substr(7) =&gt; 15) 그 후 ‘checked_cnt’에 방금 불러온 id 끝값인 cnt를 더해서 check Dict안에 있는 키 값을 만들었습니다. check['checked_cnt'+cnt]을 통해 check의 ‘checked_cnt’+cnt값이 초기에 할당된 것처럼 0일 경우 1을 할당해 주었고, $(this). addClass( on );를 통해서 아까 CSS에서 작성해둔 button. on을 활성화 했습니다. 그리고 그 값을 textarea에 전달했습니다.  반대로 ‘checked_cnt’+cnt값이 0이 아니면 0을 할당해주고 $(this). removeClass( on );로 button. on을 비활성화합니다. 그리고 button_text = button_text. replace($(this). attr('value'))를 통해 텍스트를 빼주었습니다. 🔮 결과(gif):   끝맺음오늘은 버튼클릭 이벤트를 만들어 보았습니다. CSS와 Javascript 몇줄로 간단하게 예쁜 동작을 하는 버튼을 만들 수 있었습니다. 또한, 만약 eval() 함수를 제외하고 동적 변수 할당에 대해 괜찮은 정보가 있으면 댓글로 남겨주시면 감사하겠습니다!😊 [참고자료]  https://myhappyman. tistory. com/123 예쁜 버튼 디자인 CSS 모음"
    }, {
    "id": 22,
    "url": "http://localhost:4000/javascript-modal/",
    "title": "자바스크립트 예쁜 모달창 만들기",
    "body": "2022/05/04 -  💡 Intro: 웹 페이지에 예쁜 모달창을 만드는 방법을 공부해보려 합니다. 🙌 🔎 팝업창? 모달창?: 1) 팝업창  팝업창이란, 현재 열려있는 브라우저 페이지에 또 다른 브라우저 페이지를 띄우는 것을 의미합니다.  창 + 창n의 개념을 가지며, 보통 웹 시작과 동시에 띄우는 형태로 사용합니다.  사용 의도 관점 - 사용자가 현재 의도하는 목적에 상관없이 뜨는 창 2) 모달창  모달창은 기존의 브라우저 페이지위에 새로운 브라우저 페이지를 띄우는 것이 아닌 레이어를 띄우는 것을 의미합니다.  기존의 페이지와 부모-자식 관계를 가지며, 사용자에게 중간중간 보여주는 경우로 많이 사용됩니다.  사용 의도 관점 - 다음 진행 혹은 특정한 행동을 처리하기 위해 필요에 의해 사용되는 창 모달(Modal) vs 논모달(Non-modal)  모달을 공부하면서 논모달을 알게 되었는데, 논모달은 “모달이지만 모달이 아니다”라고 그대로 번역할 수 있습니다.  일반적으로 모달은 부모 화면을 사용자가 컨트롤할 수 없는데, 논모달은 부모 화면을 사용자가 컨트롤할 수 있습니다. (예를 들어, 구글메세지 보내기에서 편지쓰기는 논모달이라고 할 수 있습니다. ) 이미지 1. 모달(Modal)과 논모달(Non-modal) 모달은 위의 이미지와 같이 다양하게 구분되어질 수 있습니다. 또한, 모달/논모달이 구분되어 지는 것처럼 여러 상횡에 따라 유동적으로 바뀔 수 있습니다. UXPlanet에 잘 정리된 의사결정 Framwork가 있는데, JeongChanho님이 잘 번역해서 정리해둔 이미지가 있어서 아래에 사진을 올려보았습니다.  이미지 2. 모달 의사결정 Framwork(출처 : JeongChanho) 📚 css와 자바스크립트로 모달창 만들기: 📕 1. 모달창 기초 생성하기: 📝 CSS 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455. modal-dim {   display: none;   position: fixed;   top: 0;   left: 0;   width: 100%;   height: 100%;   z-index: 1000; }. modal-dim . dim-bg {   top: 0;   left: 0;  right: 0;  width: 100%;   height: 100%;   margin: 0 auto;   background: #000;   opacity: . 4; }. modal-dim . modal-layer {   display: block; }. modal-dim . modal-top {   position: sticky;   top: 0;   left: 0;   right: 0;   z-index: 10; }. modal-dim . modal-tit {   font-size: 20px;   font-weight: 700;   color: #fff; }. modal-close {   width: 28px;   height: 28px;   border: none;   background: url('. . /img/close. png') center center no-repeat;   background-size: contain; }. board {   margin-bottom: 20px;   padding: 20px;   width: 100%;  height: 500px;  border: 1px solid #d6dae1;   box-sizing: border-box;   background: #fff; }  modal-close는 모달창 우측 상단의 X버튼을 생성하기 위해 만들었습니다. 원하시는 모양의 이미지를 삽입하면 됩니다.  . modal-dim . dim-bg는 모달창이 켜졌을 때, 주위를 어둡에 하기 위해 [opacity](https://www. w3schools. com/cssref/css3_pr_opacity. asp)를 사용했습니다. script에 show()와 hide()로 모달창을 끄고 킬 수 있는 기능을 생성했습니다.  📝 Javascript로 모달창 끄고 키기 1234567891011121314$(function () {  $( . js-modal-open ). click(function () {    $( . js-modal ). show();  });  $( . js-modal-close ). click(function () {    $( . js-modal ). hide();  });}) 📘 2. 모달창 동작하기: 작성한 css와 javascript로 모달창 코드를 작성합니다. 그리고 모달창을 켜기위한 버튼을 생성합니다.  📝 HTML 전체 메인코드 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!--모달창--&gt;&lt;div class= modal-dim js-modal &gt;  &lt;div class= dim-bg &gt;&lt;/div&gt;  &lt;div class= modal-layer &gt;    &lt;div class= modal-top &gt;      &lt;div class= modal-tit &gt;모달창 만들기&lt;/div&gt;      &lt;button type= button  class= modal-close js-modal-close &gt;&lt;/button&gt;    &lt;/div&gt;    &lt;div class= modal-container &gt;      &lt;div class= board-v2 &gt;        &lt;font size= 40 &gt;모달창 만들기&lt;/font&gt;      &lt;/div&gt;    &lt;/div&gt;  &lt;/div&gt;&lt;/div&gt;&lt;!--모달창 켜기위한 버튼--&gt;&lt;div&gt;  &lt;div&gt;모달창 만들기&lt;/div&gt;  &lt;div&gt;    &lt;div style= float:left; width:20%; &gt;      &lt;input type= button  value= modal_test  id= modal_test &gt;    &lt;/div&gt;  &lt;/div&gt;&lt;/div&gt;&lt;!--Javascript--&gt;&lt;!--id를 이용해 모달창 켜기--&gt;&lt;script type= text/javascript &gt;  $(function () {    $('#modal_test'). on('click', function (e) {      $( . js-modal ). show();    })  });&lt;/script&gt; 🔮 결과(gif): 이미지 3. 모달창 결과  끝맺음이렇게 CSS와 자바스크립트를 사용한다면 모달 기능을 쉽게 만들 수 있습니다. 또한 모달을 사용하게 되면 코드가 복잡해질 수 있다고 하는데, 모듈 또는 컴포넌트로 분리하여 사용하면 손쉽게 해결할 수 있습니다.  [참고자료]  JeongChanho - 이거도-모달-저거도-모달-이게-모람 http://yoonbumtae. com/?p=3632"
    }, {
    "id": 23,
    "url": "http://localhost:4000/mysql-offset/",
    "title": "MySQL offset 활용",
    "body": "2022/04/28 -  💡 Intro: API를 만들다보면 데이터에 페이징 처리를 해야하는 경우가 종종 있습니다. 그래서 오늘은 MySQL의 Limit과 offset으로 쉽게 페이징 처리를 하는 방법을 포스팅해보고자 합니다. 🙌 🔎 MySQL의 offset: limit이 처음부터 설정된 개수 까지의 데이터를 보여준다면, offset은 시작점부터 설정된 몇 개 이후의 데이터를 보여줍니다. 이를 이용해 쉽게 페이징 처리를 할 수 있습니다.  offset의 기본적인 사용방법은 아래와 같습니다.  123456789101112131415# 페이징 시 쿼리 - LIMIT: 행을 얼마나 가져올지, OFFSET: 어디서 부터 가져올지# 숫자 만큼의 행을 출력# 문법: SELECT * FROM 테이블명 ORDERS LIMIT 숫자;SELECT * FROM USER orders LIMIT 10; # (B+1) 행 부터 A 행 만큼 출력# 문법: SELECT * FROM 테이블명 ORDERS LIMIT 숫자(A) OFFSET 숫자(B);SELECT * FROM USER ORDERS LIMIT 10 OFFSET 10;# (A+1)부터 B개의 행을 출력# 문법: SELECT * FROM 테이블명 ORDER LIMIT 숫자(A), 숫자(B);SELECT * FROM USER ORDERS LIMIT 0, 10; 다른 유용한 mysql명령어는 아래 링크에서 확인할 수 있습니다!😀 알아두면 쓸모있는 MySQL 명령어 모음 📃 offset으로 페이징 처리하기: 먼저 한 페이지당 보여줄 데이터의 개수인 “limit”과 페이지 번호인 “page”를 받습니다.  123456limit = body. get('limit')page = body. get('page') page에 1을 뺀 수에 limit을 곱해서 우리가 사용한 offset을 만들어 줍니다.  🔍첫 페이지는 0부터 시작이기에 page에 1을 빼줍니다. 그리고 쿼리를 작성하면 간단하게 페이징이 가능한 코드를 작성할 수 있습니다.  1234567offset = (page - 1) * limitf'''select column from table order by {sort} desc limit {limit} offset {offset};''' 📝 전체 코드 12345678910111213sort = body. get('sort')limit = body. get('limit')page = body. get('page')offset = (page - 1) * limitresult = f'''select column from table order by {sort} desc limit {limit} offset {offset};'''cur. execute(result). . . [참고자료]  hhttps://liamkwo. github. io/mysql-command/"
    }, {
    "id": 24,
    "url": "http://localhost:4000/mysql-command/",
    "title": "알아두면 쓸모있는 MySQL 명령어 모음",
    "body": "2022/04/19 -  💡 Intro: 저는 아직 MySQL초보이기 때문에, 여러 명령어를 사용해 놓고도 시간이 조금 지나면 까먹을 때가 종종 있습니다(어…. 그 명령어가 뭐드라. . ?!?!). 그래서 제가 생각하기에 평소에 MySQL을 사용하다가, 알고있으면 쓸모있는 MySQL문법을 이곳에 간단하게 정리해 보려고 합니다. 🙌 🔎 알아두면 쓸모있는 MySQL 명령어 모음: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# 기존 컬럼에 AUTO_INCREMENT, PK 속성 추가# 문법: ALTER TABLE [테이블명] MODIFY [컬럼명] [타입] [속성]ALTER TABLE table MODIFY id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY;# auto_increment 다시 1로 세팅alter table &lt;table name&gt; auto_increment = 1; # 기존 테이블에 신규 컬럼 추가# 문법: ALTER TABLE [테이블명] ADD [컬럼명] [타입] [속성]ALTER TABLE table ADD name VARCHAR(30) NOT NULL;# 문자열에 공백 제거# TRIM - 문자열 좌우 공백 제거SELECT TRIM(' aabbccbbaa ');# TRIM - 문자열 좌측 공백 제거 (LEADING)SELECT TRIM(LEADING FROM ' aabbccbbaa ');# TRIM - 문자열 우측 공백 제거 (TRAILING)SELECT TRIM(TRAILING FROM ' aabbccbbaa ');# 여러 문자열을 구분하여 하나의 문자열로 합치기SELECT CONCAT_WS(' ', 'FirstName', 'LastName') full_name FROM table;# TRIM과 CONCAT_WS 응용SELECT CONCAT_WS(' ', trim(FirstName), trim(LastName)) full_name FROM table;# 데이터 베이스에 속한 테이블들의 각종 정보 확인show table status from `database`;# CASE문 : MySQL에서 CASE문은 프로그래밍 언어에서 스위치(switch)문과 비슷하지만, 다수의 조건에 하나의 반환 값은 동작하지 않는다. # 문법: SELECT CASE [컬럼명] WHEN [조건] TEHN [결과값] WHEN [조건] TEHN [결과값] . . . ELSE [결과값] END FROM [테이블명]SELECT CASE column WHEN 'N' THEN  실패  WHEN 'Y' THEN  성공  END as success_column FROM table;# 특정 문자로 시작하는 데이터 검색# 문법: SELECT [필드명] FROM [테이블명] WHERE [필드명] LIKE '특정 문자열%;SELECT * FROM member WHERE name LIKE '홍%# 특정 문자로 끝나는 데이터 검색# 문법: SELECT [필드명] FROM [테이블명] WHERE [필드명] LIKE '% 특정 문자열;SELECT * FROM member WHERE name LIKE '% 길동;# 특정 문자 포함 데이터 검색# 문법: SELECT [필드명] FROM [테이블명] WHERE [필드명] LIKE '% 특정 문자열%;SELECT * FROM member WHERE name LIKE '% 길동%;# 페이징 시 쿼리 - LIMIT: 행을 얼마나 가져올지, OFFSET: 어디서 부터 가져올지# 숫자 만큼의 행을 출력# 문법: SELECT * FROM 테이블명 ORDERS LIMIT 숫자;SELECT * FROM USER orders LIMIT 10; # (B+1) 행 부터 A 행 만큼 출력# 문법: SELECT * FROM 테이블명 ORDERS LIMIT 숫자(A) OFFSET 숫자(B);SELECT * FROM USER ORDERS LIMIT 10 OFFSET 10;# (A+1)부터 B개의 행을 출력# 문법: SELECT * FROM 테이블명 ORDER LIMIT 숫자(A), 숫자(B);SELECT * FROM USER ORDERS LIMIT 0, 10;# DB 테이블 구조 및 데이터 복사# 테이블 구조 복사CREATE TABLE IF NOT EXISTS `new_table` LIKE `old_table`;# 테이블 구조 및 데이터 복사CREATE TABLE IF NOT EXISTS `new_table` SELECT * FROM `old_table`;# 테이블 데이터 복사CREATE TABLE IF NOT EXISTS `new_table` SELECT * FROM `old_table`;# 테이블 데이터 부분 복사INSERT INTO `new_table` (컬럼1 [, 컬럼2 . . . ]) SELECT 컬럼1 [, 컬럼2 . . . ] FROM `old_table`; 페이징을 처리할 수 있는 쿼리인 [OFFSET]에 대해서는 다음 포스팅에 조금 더 자세히 다루어 보도록 하겠습니다. 😀 [참고자료]  https://zzang9ha. tistory. com/295 https://extbrain. tistory. com/ https://pangtrue. tistory. com/170"
    }, {
    "id": 25,
    "url": "http://localhost:4000/jquery-regex/",
    "title": "jQuery 정규식 [id^=] 사용해보기",
    "body": "2022/04/10 -  💡 Intro:  FastAPI로 관리자페이지를 제작 중, 앞부분이 동일한 id로 끝나는 엘리먼트들에 대한 접근이 필요해졌습니다.  jQuery에 다양한 정규식이 있다는 것은 알고 있었지만, [id^=]라는 정규식은 이번에 처음 접하게 되었습니다. 사용법도 매우 간단해서 짧게 포스팅 해보려 합니다. 🙌 🔎 jQuery정규식이란?: 정규표현식 :  특정한 규칙을 가진 문자열의 직합을 표현하는데 사용하는 형식 언어를 정규표현식이라고 합니다.  jQuery에도 search(), replace()등 다양한 정규식이 존재하는데, 기초적인 예제는 아래와 같습니다. 정규표현식 예제 이미지 1. 정규식예제 12345678910111213141516  var re = /a/     --a 가 있는 문자열  var re = /a/i    --a 가 있는 문자열, 대소문자 구분 안함  var re = /apple/  -- apple가 있는 문자열  var re = /[a-z]/  -- a~z 사이의 모든 문자  var re = /[a-zA-Z0-9]/  -- a~z, A~Z 0~9 사이의 모든 문자  var re = /[a-z]|[0-9]/ -- a~z 혹은 0~9사이의 문자  var re = /a|b|c/  -- a 혹은 b 혹은 c인 문자  var re = /[^a-z]/ -- a~z까지의 문자가 아닌 문자( ^  부정)  var re = /^[a-z]/ -- 문자의 처음이 a~z로 시작되는 문장  var re = /[a-z]$/ -- 문자가 a~z로 끝남  var re = /s$/;     -- 공백체크  var re = /^ss*$/;  -- 공백문자 개행문자만 입력 거절  var re = /^[-!#$%&amp; amp;'*+. /0-9=?A-Z^_a-z{|}~]+@[-!#$%&amp;'*+/0-9=?A-Z^_a-z{|}~]+. [-!#$%&amp; amp;'*+. /0-9=?A-Z^_a-z{|}~]+$/; --이메일 체크  var RegExpHG =  (/[ㄱ-ㅎ|ㅏ-ㅣ|가-힣]/) ; -- 한글 제거   var RegExpJS =  &lt;script[^&gt;]*&gt;(. *?)&lt;/script&gt; ; -- 스크립트 제거 📚 [id^=]사용하기: 📕 1. id가 id_로 시작하는 엘리먼트들 접근: 📝 Html 12345678910111213141516171819202122&lt;div&gt;  &lt;button id= id_1  value= id_1 &gt;&lt;/button&gt;  &lt;button id= id_2  value= id_2 &gt;&lt;/button&gt;  &lt;button id= id_3  value= id_3 &gt;&lt;/button&gt;  &lt;button id= id_4  value= id_4 &gt;&lt;/button&gt;  &lt;button id= id_5  value= id_5 &gt;&lt;/button&gt;  &lt;button id= id_6  value= id_6 &gt;&lt;/button&gt;  &lt;button id= id_7  value= id_7 &gt;&lt;/button&gt;  &lt;button id= id_8  value= id_8 &gt;&lt;/button&gt;  &lt;button id= id_9  value= id_9 &gt;&lt;/button&gt;  &lt;button id= id_10  value= id_10 &gt;&lt;/button&gt;  &lt;button id= id_11  value= id_11 &gt;&lt;/button&gt;  &lt;button id= id_12  value= id_12 &gt;&lt;/button&gt;  &lt;button id= id_13  value= id_13 &gt;&lt;/button&gt;  &lt;button id= id_14  value= id_14 &gt;&lt;/button&gt;  &lt;button id= id_15  value= id_15 &gt;&lt;/button&gt;  &lt;button id= id_16  value= id_16 &gt;&lt;/button&gt;&lt;/div&gt; 📝 jQuery 123$( [id^=id_] ). click(function(){  //id가 id_로 시작하는 엘리먼트들 접근}); 📘 2. id가 id_로 끝나는 엘리먼트들 접근: 📝 Html 12345678910111213141516171819202122&lt;div&gt;  &lt;button id= 1_id  value= 1_id &gt;&lt;/button&gt;  &lt;button id= 2_id  value= 2_id &gt;&lt;/button&gt;  &lt;button id= 3_id  value= 3_id &gt;&lt;/button&gt;  &lt;button id= 4_id  value= 4_id &gt;&lt;/button&gt;  &lt;button id= 5_id  value= 5_id &gt;&lt;/button&gt;  &lt;button id= 6_id  value= 6_id &gt;&lt;/button&gt;  &lt;button id= 7_id  value= 7_id &gt;&lt;/button&gt;  &lt;button id= 8_id  value= 8_id &gt;&lt;/button&gt;  &lt;button id= 9_id  value= 9_id &gt;&lt;/button&gt;  &lt;button id= 10_id  value= 10_id &gt;&lt;/button&gt;  &lt;button id= 11_id  value= 11_id &gt;&lt;/button&gt;  &lt;button id= 12_id  value= 12_id &gt;&lt;/button&gt;  &lt;button id= 13_id  value= 13_id &gt;&lt;/button&gt;  &lt;button id= 14_id  value= 14_id &gt;&lt;/button&gt;  &lt;button id= 15_id  value= 15_id &gt;&lt;/button&gt;  &lt;button id= 16_id  value= 16_id &gt;&lt;/button&gt;&lt;/div&gt; 📝 jQuery 1234567$( [id$=_id] ). click(function(){  //id가 _id로 끝나는 엘리먼트들 접근}); [참고자료]  https://www. nextree. co. kr/p4327/ https://dotheright. tistory. com/165 https://develop88. tistory. com/entry/Jquery-정규식-예제"
    }, {
    "id": 26,
    "url": "http://localhost:4000/lambda-cloudwatch2/",
    "title": "Amazon EventBridge로 특정시간에 자동으로 카운트해보기 -2",
    "body": "2022/04/06 -  💡 Intro:  Lambda함수를 이용해 특정시간에 자동으로 카운트를 해보려고합니다. 🙌 AWS Lambda는 실시간으로 코드를 실행할 수는 있으나, 필요시에만 함수를 실행합니다. 그래서 EventBridge를 이용해 특정 시간마다 Lambda에 트리거를 걸어 카운트를 해보려고 합니다. 📚 Amazon EventBridge 규칙 생성하기: 📕 1. Amazon EventBridge 규칙 생성하기: AWS 홈페이지에서 Amazon EventBridge에 들어갑니다.   Amazon EventBridge에서 이벤트목록에 규칙을 들어가면 규칙생성이 있는데, 다른 부분은 건들것 없이 그냥 규칙생성만 클릭해주면 됩니다.   📘 2. 규칙 세부 정보 설정하기: 📝 1단계 - 규칙 세부 정보 정의 원하는 규칙이름을 정하고, 저번 포스트에 공부하였던 Cron식을 사용할 것이기 때문에, 규칙 유형을 일정으로 하고 다음버튼을 클릭합니다.   📝 2단계 - 일정 정의 규칙2에서는 패턴을 설정하는데, 저녁 12시에 매일 Lambda에 이벤트를 줄 예정이기 때문에 다음과 같이 설정했습니다. Cron식이 궁금하다면 AWS CloudWatch로 자동 카운트 시스템 개발하기 -1를 클릭하세요!  GMT는 그리니치 평균시(Greenwich Mean Time)라고 하는데, 그냥 대한민국 서울의 시간이 필요한 저희는 GMT에 9시간을 더한 현지 시간대를 선택하시면 됩니다.  📝 3단계 - 대상 선택 대상 유형에는 각각 EventBridge 이벤트 버스, EventBridge API대상, AWS 서비스가 존재합니다. 하나의 event rule에 여러개의 대상이 등록이 가능하며, 저는 Lambda함수에 이벤트를 줄거라서 AWS서비스의 Lambda 항수를 선택했습니다.    그리고 규칙을 생성해 줍니다.   아래와 같이 생성한 규칙의 세부 정보와 상태를 바로 확인할 수 있습니다.  🔮 결과:  [참고자료]  https://velog. io/@techy-yunong/AWS-EventBridge-concept Amazon EventBridge 이벤트 버스 생성"
    }, {
    "id": 27,
    "url": "http://localhost:4000/lambda-cloudwatch1/",
    "title": "Amazon EventBridge로 특정시간에 자동으로 카운트해보기 -1",
    "body": "2022/04/04 -  💡 Intro:  Lambda함수를 이용해 특정시간에 자동으로 카운트를 해보려고합니다. 🙌 AWS Lambda는 실시간으로 코드를 실행할 수는 있으나, 필요시에만 함수를 실행합니다. 그래서 EventBridge를 이용해 특정 시간마다 Lambda에 트리거를 걸어 카운트를 해보려고 합니다. 🔎 들어가기전, 알고가기! -1: Lambda  Lambda는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있게 해주는 컴퓨팅 서비스입니다. Lambda는 고가용성 컴퓨팅 인프라에서 코드를 실행하고 서버와 운영 체제 유지 관리, 용량 프로비저닝 및 자동 조정, 코드 및 보안 패치 배포, 코드 모니터링 및 로깅 등 모든 컴퓨팅 리소스 관리를 수행할 수 있습니다. 또한 Lambda는 필요시에만 함수를 실행하며, 일일 몇 개의 요청에서 초당 수천 개의 요청까지 자동으로 확장이 가능합니다. 그리고 사용한 컴퓨팅 시간만큼만 비용을 지불하고, 코드가 실행되지 않을 때는 요금이 부과되지 않습니다. CloudWatch  CloudWatch는 Amazon Web Services(AWS) 리소스 및 AWS에서 실행되는 애플리케이션을 실시간으로 모니터링합니다. CloudWatch를 사용하여 리소스 및 애플리케이션에 대해 측정할 수 있는 변수인 지표를 수집하고 추적할 수 있으며(Amazon CloudWatch Logs), Amazon EventBridge를 이용해 특정한 이벤트를 처리할 수 도 있습니다.  EventBridge는 과거에는 Amazon CloudWatch Events라고 불렸으며, Zendesk 또는 Shopify와 같은 이벤트 소스의 실시간 데이터 스트림을 AWS Lambda 및 기타 SaaS 애플리케이션과 같은 대상으로 전송하는 이벤트 기반 애플리케이션을 대규모로 손쉽게 구축할 수 있는 서버리스 이벤트 버스입니다. 🔎 들어가기전, 알고가기! -2: 크론(Cron) 표현식이란?🤔  EventBridge는 이벤트를 세팅할때 기본적으로 크론 정규표현식을 사용합니다. 그럼 크론식이 무엇일까요?(저도 이번에 크론식을 처음 경험해 보았는데, 쓸 경우가 종종 생길 것 같아서 정리해두려고 합니다. ) 유닉스 계열의 운영체제에서 시간 기반으로 job scheduling을 하는 프로세스를 크론 표현식(Cron Expressions)라고 하며 자바 스프링의 Quartz나 Spring Scheduler에서도 사용하기도 한다고 합니다. 또한, 크론 표현식은 필드와 특수문자를 조합하여 스케쥴링을 조절할 수 있습니다.  리눅스/유닉스 크론 표현식에서는 5개의 필드를 사용하고, Quartz 기반의 크론 표현식에서는 7개의 필드를 사용하는 String 문자열입니다. 공백으로 구분하고(“ “) 각 필드는 앞에서 부터 초, 분, 시, 일, 월, 요일, 년으로 구분합니다. 크론 표현식 표현       : 모든 값    ? : 특정한 값이 없음 - : 범위를 뜻 함 (예) 월요일에서 수요일까지는 MON-WED로 표현 , : 특별한 값일 때만 동작 (예) 월,수,금 MON,WED,FRI / : 시작시간 / 단위 (예) 0분부터 매 5분 0/5 L : 일에서 사용하면 마지막 일, 요일에서는 마지막 요일(토요일) W : 가장 가까운 평일 (예) 15W는 15일에서 가장 가까운 평일 (월 ~ 금)을 찾음 # : 몇째주의 무슨 요일을 표현 (예) 3#2 : 2번째주 수요일 크론 표현식 예제  크론 표현식에 대해 공부를 하면서 느낀점은, 어느정도만 알면 전혀 어렵지 않다는 것입니다. 표를 보고 대충 이해하여 한번만 만들어봐도 다음 부터는 쉽게 만들 수 있습니다. 😀 CronMaker라는 원하는 크론 표현식을 생성해 주는 사이트 존재합니다. 대충 크론 표현식을 만든 후, 내가 만든 크론 표현식을 입력하고 Calcurate next dates 버튼을 클릭하면, 내가 만든 크론 표현식으로 언제 실행될것인지 미리 볼수 있는 기능도 존재합니다. 📚 Lambda 코드작성: 📕 1. Lambda 함수생성: 아래와 같이 본인이 사용하는 언어를 선택한 후, Lambda 함수를 생성합니다. 그리고 VPC및 함수에 필요한 Lambda Layer를 설정합니다.   📘 2. Lambda 코드작성: 자동으로 카운트 해주어야할 데이터를 조건에 따라서 가짓 수를 나누어 주었습니다. 저는 필요에 따라 S3와 RDS를 연결하였습니다.  12345678910111213141516171819202122import jsonimport base64, os, boto3, ast, copyimport jsonimport pymysqlimport ast import db_configAISCAN_URL = ''rds_host = db_config. rds_hostname = db_config. namepassword = db_config. passworddb_name = db_config. db_name ########### init s3 bucket infos3 = boto3. resource('s3') bucket_name = ''def lambda_handler(event, context):   conn = pymysql. connect(rds_host, user=name, passwd=password, db=db_name, connect_timeout=5)    c_query = ''   print(event)    with conn. cursor(pymysql. cursors. DictCursor) as cur:    . . . Amazon EventBridge 규칙 생성은 다음 포스팅에 이어서 작성을 해보도록 하겠습니다. 😀 "
    }, {
    "id": 28,
    "url": "http://localhost:4000/fastapi-multipledb/",
    "title": "FastAPI에 2개 이상의 DB연동하기",
    "body": "2022/03/30 -  💡 Intro:  원래 flask를 주로 사용하는데 지인분의 추천으로 FastAPI를 알게 되었습니다. FastAPI에서 libuv(node. js 성능의 핵심)를 코어로 사용하는 uvloop가 너무 매력적 이었고, ASGI를 한번 사용해보고싶어서 FastAPI를 한번 사용해볼까. . ? 라는 마음으로 사용해 보게 되었습니다.  FastAPI로 관리자 웹을 만들다가 기존에 연결해 두었던 DB에 한개를 추가로 더 연결해서 MultipleDatabases를 구성해야하는 상황이 발생했습니다. 생각보다 reference가 많이 없었는데, FastAPI의 제작자이신 tiangolo님의 issues에서 이 문제를 찾을 수 있었습니다. Multipledatabases에 대해 다양한분들의 의견이 잘 정리되어있어서 이를 저의 FastAPI에 적용한것을 정리해보려고 합니다. 🙌 🔎 그전에! FastAPI란?: 공식 문서에는 다음과 같이 설명되어져 있습니다. FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3. 6+ based on standard Python type hints. 주요기능:  Fast: NodeJS 및 Go와 비슷한 성능, 현존하는 파이썬 웹 프레임워크 중 가장 빠르다.  Fast to code Fewer bugs Intuitive Easy Short: 적은버그와 코드중복을 최소화할 수 있고, 각 매개변수 선언에 여러기능을 제공해준다.  Robust: 문서 자동화 및 쉬운 배포가 가능하다.  Standards-based: 개방형 API 표준(OpenAPI&amp;JSON)을 기반으로 한다. 이것만 아니라, 현재 아직 많은 레퍼런스가 나와있지는 않지만 그것을 매꿔줄 매우매우 수준높은 공식문서가 잘 마련되어져 있었습니다. 또한 백엔드 엔지니어 입장에서 API를 사용할 수 있도록 만든 문서 작업이 생각보다 많은 시간이 소요되는데, FastAPI는 문서의 자동화를 제공해줌으로써 개발자가 문서 작업에 할애하는 시간을 줄이고 오직 코드에만 집중할 수 있도록 해주어서 업무 효율을 증진 시켜줄 수 있습니다.  📚 Multiple databases 설정하기: 📕 1. settings. py: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import osfrom functools import lru_cachefrom pydantic import BaseSettings_VERSION_ =  0. 1. 0 ###multiple databases-1class ISettings(BaseSettings):  db_engine: str =  mysql+pymysql   db_host: str =     db_user: str =  root   db_password: str =     db_port: int = 3306  db_database: str =     debug: bool = True  kakao_rest_key =     @property  def db_dsn(self):    dsn = f {self. db_engine}://{self. db_user}:{self. db_password}@{self. db_host}:{self. db_port}/{self. db_database}     return dsn  class DevelopmentSettings(ISettings):  passclass ProductionSettings(ISettings):  debug = False###multiple databases-2class ISettings2(BaseSettings):  db_engine: str =  mysql+pymysql   db_host: str =     db_user: str =  admin   db_password: str =     db_port: int = 3306  db_database: str =     debug: bool = True  kakao_rest_key =     @property  def db_dsn(self):    dsn = f {self. db_engine}://{self. db_user}:{self. db_password}@{self. db_host}:{self. db_port}/{self. db_database}     return dsn  class DevelopmentSettings2(ISettings2):  passclass ProductionSettings2(ISettings2):  debug = False@lru_cache()def get_settings():  config = os. environ. get( FASTAPI_CONFIG ,  default )  configs = {     development : DevelopmentSettings,     production : ProductionSettings,     default : DevelopmentSettings,  }  return configs. get(config, DevelopmentSettings)()@lru_cache()def get_settings2():  config = os. environ. get( FASTAPI_CONFIG ,  default )  configs = {     development : DevelopmentSettings2,     production : ProductionSettings2,     default : DevelopmentSettings2,  }  return configs. get(config, DevelopmentSettings2)() 📌 functools - @lru_cache** : LRU(Least Recently Used)캐싱을 사용하기위해 @lru_cache를 사용했습니다. @lru_cache 데코레이터는 functools 내장 모듈로 부터 불러올 수 있으며, @lru_cache 를 아무 함수 위에 선언하면 사용하면 그 함수에 넘어온 인자를 키(key)로 함수의 호출 결과를 값(value)으로 LRU캐싱이 적용됩니다.  📘 2. database. py: 1234567891011121314151617181920212223242526272829303132333435from sqlalchemy import create_enginefrom sqlalchemy. ext. declarative import declarative_basefrom sqlalchemy. orm import sessionmakerfrom api. settings import get_settings, get_settings2Base_1 = declarative_base()Base_2 = declarative_base()SQLALCHEMY_DATABASE_URL = get_settings(). db_dsnSQLALCHEMY_DATABASE_URL2 = get_settings2(). db_dsn###multiple databases-1engine1 = create_engine(SQLALCHEMY_DATABASE_URL)SessionLocal1 = sessionmaker(autocommit=False, autoflush=False, bind=engine1)###multiple databases-2engine2 = create_engine(SQLALCHEMY_DATABASE_URL2)SessionLocal2 = sessionmaker(autocommit=False, autoflush=False, bind=engine2)def get_db():  session = SessionLocal1()  try:    yield session    session. commit()  finally:    session. close()    def get_db2():  session = SessionLocal2()  try:    yield session    session. commit()  finally:    session. close()📌 sqlalchemy : SQL 문법 없이 개발 중인 언어로 데이터베이스에 접근할 수 있게 해주는 라이브러리를 ORM(Object Relational Mapping) 이라고 합니다. 그 중에서도 sqlalchemy은 python의 대표적인 ORM입니다.  📒 3. model. py: 12345678from api. database import Base_1, Base_2 from api. models. base_model import ModelBaseclass DB_Schema1(Base_1, ModelBase):  __tablename__ =  DB_Schema1_table class DB_Schema2(Base_2, ModelBase):  __tablename__ =  DB_Schema2_table  📗 4. route. py: 123456789101112131415161718192021222324from fastapi import APIRouter, Depends, Bodyfrom api. database import get_db, get_db2router = APIRouter()@router. get(   /items/get_db1 , description= multiple DB )async def get_db1(  db=Depends(get_db),):    return True    @router. get(   /items/get_db2 , description= multiple DB )async def get_db2(  db=Depends(get_db2),):    return True [참고자료]  https://blog. neonkid. xyz/253 pydantic - BaseSettings FastAPI - pydantic BaseSettings예제"
    }, {
    "id": 29,
    "url": "http://localhost:4000/lambda-bootpay/",
    "title": "AWS Lambda에 Bootpay연동하기 - 결제 검증",
    "body": "2022/03/15 -  💡 Intro: BootPay는 무료로 서비스되는 결제 검증 API입니다. 초기에 일반 PG 사와 별도의 계약 없이 개발을 먼저 할 수 있어서, 인앱 결제가 급하게 필요했던 저는 BootPay를 이용하기로 했습니다. 간단하게 사용방법을 정리해 보도록 하겠습니다. (매우 간단해요!)🙌 🔎 Bootpay란?: 부트페이는 개발자를 위한 결제연동 서비스로, 구글 애널리틱스와 같이 결제 데이터 분석 서비스를 제공합니다. 또한 웹, 앱 SDK 모두 지원하며 국내외 여러 PG(복수 선택 가능)와 결제수단을 소스코드 한 줄로 사용할 수 있으므로 불필요한 작업을 줄일 수 있습니다.  📚 결제 검증: 부트페이 측에서는 결제 검증에 대해, 이렇게 설명하고 있습니다. 결제 검증을 해야하는 이유  결제 연동은 Client Side에서 동작되기 때문에 결제 금액 및 결제 상태에 대한 변조가 가능하다고 합니다. 그러므로 반드시 처음 요청했던 금액과 결제가 올바르게 이루어졌는지에 대해 서버사이드에서 서버로 영수증 키를 보내 확인하는 과정을 거쳐야 합니다. 그렇다면 결제 검증을 무조건 해야하나요?  결제 검증을 하지 않더라도 PG사에서 제공하는 결제 로직을 모두 완료할 수 있습니다. 방금 말했다시피, 실제 결제가 이루어지지만 Client Side에서 언제든 변조된 데이터를 구현하신 서버로 보내 부정적인 방법으로 구매 완료 데이터를 보낼 수 있기 때문에, 결제 검증은 필수로 하는것이 좋다고 Bootpay에서는 설명하고 있습니다. 📕 1. Lambda layer생성: Bootpay 결제 검증 및 취소 모듈(python)을 다운 받은 뒤, 아래와 같이 Lambda layer를 생성합니다.   📘 2. Add a layer: 생성한 Bootpay layer를 Lambda함수에 추가해 줍니다.   그리고 import합니다.  1from lib. BootpayApi import BootpayApi 📒 3. 검증코드 작성하기: 아래와 같이 검증코드만 작성하면 매우 간단하게 결제 검증을 끝낼 수 있습니다. 😀 저는 웹결제가 없었기 떄문에 앱에서 결제 후 서버사이드에서 결제 검증만 진행하였으며, application_id와 private_key는 Bootpay 관리자에서 확인할 수 있습니다. 또한 아래 코드와 같이 결제 금액으로 비교를 해주면 되는데, 가격말고도 원하는 다른 데이터를 추가로 비교할 수 도있습니다.  123456789101112131415from lib. BootpayApi import BootpayApibootpay = BootpayApi(  '[[ application_id ]]',  '[[ private_key ]]')result = bootpay. get_access_token()if result['status'] is 200:  verify_result = bootpay. verify('[[ receipt_id ]]')  if verify_result['status'] is 200:    # 원래 주문했던 금액이 일치하는가?    # 그리고 결제 상태가 완료 상태인가?    if verify_result['data']['status'] is 1 and verify_result['data']['price'] is price:      # TODO: 이곳이 상품 지급 혹은 결제 완료 처리를 하는 로직으로 사용하면 됩니다. 🔮 검증결과: 123456789101112131415161718192021222324252627282930313233343536{  status : 200,  code : 0,  message :   ,  data : {   receipt_id :   ,   order_id :  12345678910 ,   name :  테스트음식 ,   price : 3000,   unit :  krw ,   pg :  kcp ,   method :  card ,   pg_name :  KCP ,   method_name :  카드결제 ,   payment_data : {    card_name :  BC카드 ,    card_no :   ,    card_quota :  00 ,    card_auth_no :   ,    receipt_id :   ,    n :  테스트음식 ,    p : 3000,    pg :  KCP ,    pm :  카드결제 ,    pg_a :  kcp ,    pm_a :  card ,    o_id :   ,    p_at :  2021-12-27 ,    s : 1,    g : 2  },   requested_at :  2021-12-27 16:47:52 ,   purchased_at :  2021-12-27 16:48:53 ,   status : 1 }} 결제가 완료되면 “s”값이 1이 나옵니다. “status”의 경우 현재 결제의 상태를 보여주는데, 다음과 같이 나타낼 수 있습니다.  123456789101112gist4결제 상태 ( 현재 결제의 상태를 나타냅니다. 결제 검증에서 가장 중요한 지표가 됩니다. )0 - 결제 대기 상태입니다. 승인이 나기 전의 상태입니다. 1 - 결제 완료된 상태입니다. 2 - 결제승인 전 상태입니다. transactionConfirm() 함수를 호출하셔서 결제를 승인해야합니다. 3 - 결제승인 중 상태입니다. PG사에서 transaction 처리중입니다. 20 - 결제가 취소된 상태입니다. -20 - 결제취소가 실패한 상태입니다. -30 - 결제취소가 진행중인 상태입니다. -1 - 오류로 인해 결제가 실패한 상태입니다. -2 - 결제승인이 실패하였습니다. 서류작성 및 PG사 심사(앱 결제테스트 등)는 거의 3주 가까이 걸렸는데, 서버사이드의 작업은 3시간도 채 걸리지 않고 작업을 끝낼 수 있었습니다. 또한 Bootpay 개발자와 원할한 소통도 가능하고 Bootpay 버그에 대한 수정 요청도 빠르게 처리해 주기 때문에,(우리는 앱단에서 요청사항이 있었는데, 4일내로 업데이트 해주셨음…)저 처럼 빠른시일내 앱결제 시스템이 필요한경우가 있으신분은 Bootpay를 한번 고려해보는것도 좋은 선택인것 같습니다!😛 [참고자료]  https://docs. bootpay. co. kr/rest/verify 페이앱-api로-연동하기-결제-검증"
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});